{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright **`(c)`** 2022 Giovanni Squillero `<squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Lab 3: Policy Search\n",
    "\n",
    "## Task\n",
    "\n",
    "Write agents able to play [*Nim*](https://en.wikipedia.org/wiki/Nim), with an arbitrary number of rows and an upper bound $k$ on the number of objects that can be removed in a turn (a.k.a., *subtraction game*).\n",
    "\n",
    "The goal of the game is to **avoid** taking the last object.\n",
    "\n",
    "* Task3.1: An agent using fixed rules based on *nim-sum* (i.e., an *expert system*)\n",
    "* Task3.2: An agent using evolved rules\n",
    "* Task3.3: An agent using minmax\n",
    "* Task3.4: An agent using reinforcement learning\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Create the directory `lab3` inside the course repo \n",
    "* Put a `README.md` and your solution (all the files, code and auxiliary data if needed)\n",
    "\n",
    "## Notes\n",
    "\n",
    "* Working in group is not only allowed, but recommended (see: [Ubuntu](https://en.wikipedia.org/wiki/Ubuntu_philosophy) and [Cooperative Learning](https://files.eric.ed.gov/fulltext/EJ1096789.pdf)). Collaborations must be explicitly declared in the `README.md`.\n",
    "* [Yanking](https://www.emacswiki.org/emacs/KillingAndYanking) from the internet is allowed, but sources must be explicitly declared in the `README.md`.\n",
    "\n",
    "**Deadline**\n",
    "\n",
    "T.b.d.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "import copy\n",
    "from math import sqrt, exp, isclose\n",
    "from typing import Callable\n",
    "from collections import namedtuple\n",
    "from itertools import accumulate\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import stdev, mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_HEAPS = 3\n",
    "N_GAMES = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "random.seed(13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, name: str, strategy: Callable, *strategy_args):\n",
    "        self._strategy = strategy\n",
    "        self._strategy_args = strategy_args\n",
    "        self._name = name\n",
    "        self._loser = False\n",
    "        self._n_plies = 0\n",
    "\n",
    "    def ply(self, state):\n",
    "        self._strategy(self, state, *self._strategy_args)\n",
    "        self._n_plies += 1\n",
    "\n",
    "    @property\n",
    "    def loser(self):\n",
    "        return self._loser\n",
    "\n",
    "    @loser.setter\n",
    "    def loser(self, val):\n",
    "        self._loser = val\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "\n",
    "    @property\n",
    "    def n_plies(self):\n",
    "        return self._n_plies\n",
    "\n",
    "    @n_plies.setter\n",
    "    def n_plies(self, val):\n",
    "        self._n_plies = val\n",
    "\n",
    "    def flush_parameters(self):\n",
    "        self._n_plies = 0\n",
    "        self._loser = False\n",
    "\n",
    "\n",
    "class Nim:\n",
    "    def __init__(self, num_rows: int = None, rows: list = None, k: int = None) -> None:\n",
    "        if num_rows is not None:\n",
    "            self._rows = [i*2 + 1 for i in range(num_rows)]\n",
    "        else:\n",
    "            self._rows = rows\n",
    "        self._k = k\n",
    "\n",
    "    def nimming(self, row: int, num_objects: int, player: Player) -> None:\n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert self._k is None or num_objects <= self._k\n",
    "        logging.debug(f\"Heaps at player {player.name} turn: {self._rows}\")\n",
    "        logging.debug(\n",
    "            f\"Player {player.name} takes {num_objects} from heap {row}\")\n",
    "        self._rows[row] -= num_objects\n",
    "        if sum(self._rows) == 0:\n",
    "            player.loser = True\n",
    "\n",
    "    @property\n",
    "    def rows(self):\n",
    "        return self._rows\n",
    "\n",
    "    def copy(self):\n",
    "        return copy.deepcopy(self)\n",
    "\n",
    "\n",
    "def play(A: Player, B: Player, state: Nim) -> Player:\n",
    "    while not (A.loser or B.loser):\n",
    "        A.ply(state)\n",
    "        if not A.loser:\n",
    "            B.ply(state)\n",
    "    if A.loser:\n",
    "        return B\n",
    "    elif B.loser:\n",
    "        return A\n",
    "\n",
    "\n",
    "def match(A: Player, B: Player, state: Nim, n_games: int):\n",
    "    winners = list()\n",
    "    for i in range(n_games):\n",
    "        initial_state = state.copy()\n",
    "        A.flush_parameters()\n",
    "        B.flush_parameters()\n",
    "        r = random.random()\n",
    "        if r <= 0.5:\n",
    "            w = play(A, B, initial_state)\n",
    "        else:\n",
    "            w = play(B, A, initial_state)\n",
    "        winners.append((w.name, w.n_plies))\n",
    "    return winners\n",
    "\n",
    "\n",
    "def print_match_result(A: Player, B: Player, res: list):\n",
    "    n_A_win = 0\n",
    "    n_games = len(res)\n",
    "    for i in range(n_games):\n",
    "        if res[i][0] == A.name:\n",
    "            n_A_win += 1\n",
    "    print(f\"{A.name} won {n_A_win} times\\n{B.name} won {n_games - n_A_win} times\")\n",
    "\n",
    "\n",
    "def random_strategy(player: Player, heaps: Nim, decrement: bool = False):\n",
    "    non_zero_heaps_idxs = [i for i, v in enumerate(\n",
    "        heaps.rows) if v > 0]  # choose a random non-zero heap\n",
    "    idx_heap = random.choice(non_zero_heaps_idxs)\n",
    "    if decrement:\n",
    "        quantity = 1\n",
    "    else:\n",
    "        # decrease it of a random quantity\n",
    "        quantity = random.randint(1, heaps.rows[idx_heap])\n",
    "    heaps.nimming(idx_heap, quantity, player)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task3.1 Nim-Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nim_sum(l: list):\n",
    "    sum = 0\n",
    "    for _, v in enumerate(l):\n",
    "        sum ^= v\n",
    "    return sum\n",
    "\n",
    "\n",
    "def check_critical_situations(heaps: list) -> int:\n",
    "    n_heaps = len(heaps)\n",
    "    n_heaps_to_zero = len([i for i, h in enumerate(heaps) if h == 0])\n",
    "    n_heaps_to_one = len([i for i, h in enumerate(heaps) if h == 1])\n",
    "    n_heaps_greater_than_zero = n_heaps - n_heaps_to_zero\n",
    "    n_heaps_greater_than_one = n_heaps_greater_than_zero - n_heaps_to_one\n",
    "\n",
    "    # [1, a, 1, 1, 0, 0], a > 1\n",
    "    if n_heaps_greater_than_zero % 2 == 0 and n_heaps_greater_than_one == 1:\n",
    "        return 1\n",
    "    # [1, a, 1, 0, 0], a > 1\n",
    "    if n_heaps_greater_than_zero % 2 == 1 and n_heaps_greater_than_one == 1:\n",
    "        return 2\n",
    "    # [a, 0, 0], a > 1\n",
    "    if n_heaps_greater_than_one == 1 and n_heaps_to_one == 0:\n",
    "        return 3\n",
    "    # [1, 1, 1, 1, 0, ..., 0] no need to manage this explicitly\n",
    "    if n_heaps_to_one % 2 == 0 and n_heaps_to_zero + n_heaps_to_one == n_heaps:\n",
    "        return 4\n",
    "    # [0, 0, ..., 0] the player has won\n",
    "    if n_heaps_to_zero == n_heaps:\n",
    "        return 5\n",
    "    # [1, 1, 1, 0, ..., 0]\n",
    "    if n_heaps_to_one % 2 == 1 and n_heaps_to_zero + n_heaps_to_one == n_heaps:\n",
    "        return -1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def critical_situations(player: Player, heaps: Nim) -> bool:\n",
    "\n",
    "    code = check_critical_situations(heaps.rows)\n",
    "\n",
    "    if code != 0:\n",
    "        if code == 1:  # [1, a, 1, 1, 0, 0], a > 1\n",
    "            # take all objects from the heap with more than 1 object\n",
    "            heaps.nimming(heaps.rows.index(max(heaps.rows)),\n",
    "                          max(heaps.rows), player)\n",
    "        elif code == 2:  # [1, a, 1, 0, 0], a > 1\n",
    "            # take all objects but 1 from the heap with more than 1 object\n",
    "            heaps.nimming(heaps.rows.index(max(heaps.rows)),\n",
    "                          max(heaps.rows)-1, player)\n",
    "        elif code == 3:  # [a, 0, 0], a > 1\n",
    "            # take all objects but 1 from the last non zero heap with more than 1 object\n",
    "            heaps.nimming(heaps.rows.index(max(heaps.rows)),\n",
    "                          max(heaps.rows)-1, player)\n",
    "        # [1, 1, 0, ..., 0] or [1, 1, 1, 0, ..., 0]\n",
    "        elif code == 4 or code == -1:\n",
    "            # take from the first non zero heap\n",
    "            heaps.nimming(heaps.rows.index(1), 1, player)\n",
    "        elif code == 5:\n",
    "            pass\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def nim_sum_strategy(player: Player, heaps: Nim):\n",
    "    if sum(heaps.rows) == 0:\n",
    "        raise Exception(\"There is no heap left!\")\n",
    "\n",
    "    logging.debug(\n",
    "        f\"Player: {player.name}, heaps nim-sum: {nim_sum(heaps.rows)}\")\n",
    "\n",
    "    if not critical_situations(player, heaps):\n",
    "        # normal game\n",
    "        x = nim_sum(heaps.rows)\n",
    "        y = [nim_sum([x, h]) for _, h in enumerate(heaps.rows)]\n",
    "        winning_heaps = [i for i, h in enumerate(heaps.rows) if y[i] < h]\n",
    "        if len(winning_heaps) > 0:  # if there's a winning heap\n",
    "            chosen_heap_idx = random.choice(winning_heaps)\n",
    "            quantity = heaps.rows[chosen_heap_idx]-y[chosen_heap_idx]\n",
    "            heaps.nimming(chosen_heap_idx, quantity, player)\n",
    "        else:  # take from a random heap\n",
    "            random_strategy(player, heaps)\n",
    "\n",
    "    logging.debug(\n",
    "        f\"Heaps nim-sum after player {player.name} move: {nim_sum(heaps.rows)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice won 99 times\n",
      "Bob won 1 times\n"
     ]
    }
   ],
   "source": [
    "# trying nim-sum vs random strategy\n",
    "heaps = Nim(N_HEAPS)\n",
    "Alice = Player(\"Alice\", nim_sum_strategy)\n",
    "Bob = Player(\"Bob\", random_strategy)\n",
    "winners = match(Alice, Bob, heaps, N_GAMES)\n",
    "print_match_result(Alice, Bob, winners)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice won 58 times\n",
      "Bob won 42 times\n"
     ]
    }
   ],
   "source": [
    "# trying nim-sum vs nim-sum strategy\n",
    "heaps = Nim(N_HEAPS)\n",
    "Alice = Player(\"Alice\", nim_sum_strategy)\n",
    "Bob = Player(\"Bob\", nim_sum_strategy)\n",
    "winners = match(Alice, Bob, heaps, N_GAMES)\n",
    "print_match_result(Alice, Bob, winners)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task3.2 Evolved Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "GENERATIONS = 1_000\n",
    "POP_SIZE = 500\n",
    "OFFSPR_NUM = 5*POP_SIZE\n",
    "FITNESS_N_GAMES = N_GAMES  # number of games upon which to evaluate the fitness\n",
    "# act as a penalty to the fitness, to prefer smaller genomes (NOT ACTUALLY NEEDED)\n",
    "GEN_SIZE_PENALTY = 0\n",
    "SURVIVOR_FRAC = 0.2  # fraction on survivors after extinction\n",
    "EXT_CNT = 5  # number of generations after which an extinction can happen, None to deactivate extinction\n",
    "NICHES = 5  # number of niches, None to deactivate niches\n",
    "ALPHA_XOVER = 0.5  # how much of one parent to pass to the children in crossover\n",
    "# ratio between the max genome size and the number of heaps, used in initialization to roughly control genome size\n",
    "MAX_GEN_SIZE_RATIO_INIT = 100\n",
    "FITNESS_STRATEGY = nim_sum_strategy  # strategy used to train the algorithm\n",
    "MIGRANT_FRAC = 0.1  # fraction of migrants individual in niching\n",
    "# min increase of the mean fitness below which it is considered converged, if 1 is always converged, 0 is never\n",
    "CONVERGENCE_THRESHOLD = 0.01\n",
    "MAX_BEST_FITNESS = 0.5  # to avoid overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a condition is represented by a list of numbers + character '#' for don't care\n",
    "# with the following meaning: heaps[i] = condition[i] and heaps[i+] = condition[i+] and etc...\n",
    "# an action is represented by a tuple of two numbers: the heap index and\n",
    "# the quantity to be take from it.\n",
    "# the max size of the genome is the number of possible actions times the number of possible conditions\n",
    "# that is, if h(i) is the size of the i-th heap, (∏(h(i)+1)*∑h(i) for i=0, 1, ..., n-1\n",
    "# of course this does not scale, so the size of the genome will be an evolved parameter.\n",
    "\n",
    "class Genome:\n",
    "    def __init__(self, conditions: list, actions: list, genome_size: int, step_size: float, mutation_rate: float, fitness: float = None):\n",
    "        self._conditions = conditions\n",
    "        self._actions = actions\n",
    "        self._genome_size = genome_size\n",
    "        self._step_size = step_size\n",
    "        self._mutation_rate = mutation_rate\n",
    "        self._fitness = fitness\n",
    "\n",
    "    @property\n",
    "    def conditions(self):\n",
    "        return self._conditions\n",
    "\n",
    "    @property\n",
    "    def actions(self):\n",
    "        return self._actions\n",
    "\n",
    "    @property\n",
    "    def genome_size(self):\n",
    "        return self._genome_size\n",
    "\n",
    "    @property\n",
    "    def fitness(self):\n",
    "        return self._fitness\n",
    "\n",
    "    @fitness.setter\n",
    "    def fitness(self, val):\n",
    "        self._fitness = val\n",
    "\n",
    "    @property\n",
    "    def step_size(self):\n",
    "        return self._step_size\n",
    "\n",
    "    @property\n",
    "    def mutation_rate(self):\n",
    "        return self._mutation_rate\n",
    "\n",
    "    def check_conditions(self, heaps: list) -> tuple:\n",
    "        for i, cond in enumerate(self._conditions):\n",
    "            found = True\n",
    "            for j, v in enumerate(cond):\n",
    "                if heaps[j] != v and v != '#':\n",
    "                    found = False\n",
    "                    break\n",
    "            if found:\n",
    "                return self._actions[i]\n",
    "        return None\n",
    "\n",
    "    def mutate(self, heaps: list, tau: float) -> None:\n",
    "        # mutate step size\n",
    "        self._step_size = self._step_size*exp(tau*random.gauss(0, 1))\n",
    "\n",
    "        # mutate mutation rate\n",
    "        self._mutation_rate = self._mutation_rate + \\\n",
    "            self._step_size*random.gauss(0, 1)\n",
    "        if self._mutation_rate > 1:\n",
    "            self._mutation_rate = 1\n",
    "        elif self._mutation_rate < 0:\n",
    "            self._mutation_rate = 0\n",
    "\n",
    "        # mutate conditions\n",
    "        new_conditions = list()\n",
    "        for cond in self._conditions:\n",
    "            new_cond = list()\n",
    "            for i, c in enumerate(cond):\n",
    "                symbols = [h for h in range(1, heaps[i]+1)]\n",
    "                symbols.append('#')\n",
    "\n",
    "                r = random.random()\n",
    "                if r < self._mutation_rate:\n",
    "                    new_cond.append(random.choice(symbols))\n",
    "                else:\n",
    "                    new_cond.append(c)\n",
    "\n",
    "            new_conditions.append(new_cond)\n",
    "\n",
    "        # mutate actions\n",
    "        new_actions = list()\n",
    "        for act in self._actions:\n",
    "\n",
    "            # mutate the heap idx\n",
    "            r = random.random()\n",
    "            if r < self._mutation_rate:\n",
    "                heap_idx = random.randint(0, len(heaps)-1)\n",
    "            else:\n",
    "                heap_idx = act[0]\n",
    "\n",
    "            # mutate the quantity\n",
    "            max_q = heaps[heap_idx]\n",
    "            s = random.random()\n",
    "            if s < self._mutation_rate:\n",
    "                quant = random.randint(1, max_q)\n",
    "            else:\n",
    "                quant = act[1]\n",
    "\n",
    "            new_actions.append((heap_idx, quant))\n",
    "\n",
    "        # mutate genome size\n",
    "        old_genome_size = self._genome_size\n",
    "        self._genome_size = int(\n",
    "            self._genome_size + self._step_size*random.gauss(0, 1))\n",
    "        if self._genome_size <= 0:\n",
    "            self._genome_size = 1\n",
    "        diff = self._genome_size - old_genome_size\n",
    "\n",
    "        if diff < 0:\n",
    "            # pop elements until the right size\n",
    "            while diff != 0:\n",
    "                idx = random.choice(range(len(new_conditions)))\n",
    "                new_conditions.pop(idx)\n",
    "                new_actions.pop(idx)\n",
    "                diff += 1\n",
    "\n",
    "        elif diff > 0:\n",
    "            # fill in with random\n",
    "            for i in range(diff):\n",
    "                new_conditions.append(gen_random_condition(heaps))\n",
    "                new_actions.append(gen_random_action(heaps))\n",
    "\n",
    "        assert len(new_actions) == self._genome_size\n",
    "        assert len(new_conditions) == self._genome_size\n",
    "\n",
    "        # finally\n",
    "        self._conditions = new_conditions\n",
    "        self._actions = new_actions\n",
    "\n",
    "\n",
    "def gen_random_condition(heaps: list) -> list:\n",
    "    condition = list()\n",
    "    for i, heap in enumerate(heaps):  # for each heap\n",
    "        n = [h for h in range(1, heap + 1)]  # find the possible conditions\n",
    "        n.append('#')                       # add a don't care condition\n",
    "        # choose it and add it to the list of conditions\n",
    "        condition.append(random.choice(n))\n",
    "    return condition\n",
    "\n",
    "\n",
    "def gen_random_action(heaps: list) -> tuple:\n",
    "    heap_idx = random.randint(0, len(heaps)-1)\n",
    "    quantity = random.randint(1, heaps[heap_idx])\n",
    "    return (heap_idx, quantity)\n",
    "\n",
    "\n",
    "def initialization(pop_size: int, heaps: Nim) -> list:\n",
    "    population = list()\n",
    "    n_heaps = len(heaps.rows)\n",
    "    max_genome_size = MAX_GEN_SIZE_RATIO_INIT*n_heaps\n",
    "\n",
    "    for _ in range(pop_size):\n",
    "        genome_size = random.randint(n_heaps, max_genome_size)\n",
    "        conditions = [gen_random_condition(heaps.rows)\n",
    "                      for _ in range(genome_size)]\n",
    "        actions = [gen_random_action(heaps.rows) for _ in range(genome_size)]\n",
    "        step_size = random.random()\n",
    "        mutation_rate = random.random()\n",
    "        g = Genome(conditions, actions, genome_size,\n",
    "                   step_size, mutation_rate, None)\n",
    "        g.fitness = fitness(g, heaps, FITNESS_STRATEGY)\n",
    "        population.append(g)\n",
    "\n",
    "    return population\n",
    "\n",
    "\n",
    "class EvolutionalPlayer(Player):\n",
    "    def __init__(self, name: str, genome: Genome, strategy: Callable):\n",
    "        super().__init__(name, strategy)\n",
    "        self._genome = genome\n",
    "\n",
    "    @property\n",
    "    def genome(self):\n",
    "        return self._genome\n",
    "\n",
    "\n",
    "def termination_condition(cur_gen: int, stats: list):\n",
    "    best_fitness = stats[-1][1]\n",
    "    if cur_gen >= GENERATIONS or best_fitness >= MAX_BEST_FITNESS:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def evolved_strategy(player: EvolutionalPlayer, heaps: Nim) -> None:\n",
    "    action = player.genome.check_conditions(heaps.rows)\n",
    "\n",
    "    # check if an action is possible\n",
    "    # if not act randomly\n",
    "    if action is not None and heaps.rows[action[0]] >= action[1]:\n",
    "        heaps.nimming(action[0], action[1], player)\n",
    "    else:\n",
    "        non_zero_heaps = [i for i, h in enumerate(heaps.rows) if h > 0]\n",
    "        assert len(non_zero_heaps) > 0\n",
    "        h_idx = random.choice(non_zero_heaps)\n",
    "        q = random.randint(1, heaps.rows[h_idx])\n",
    "        heaps.nimming(h_idx, q, player)\n",
    "\n",
    "\n",
    "def fitness(individual: Genome, heaps: Nim, strategy: Callable) -> float:\n",
    "    this_player = EvolutionalPlayer(\n",
    "        \"this_player\", individual, evolved_strategy)\n",
    "    opponent = Player(\"opponent\", strategy)\n",
    "    winners = match(this_player, opponent, heaps, FITNESS_N_GAMES)\n",
    "    n_win = 0\n",
    "    for w in winners:\n",
    "        if w[0] == \"this_player\":\n",
    "            n_win += 1\n",
    "    return n_win/FITNESS_N_GAMES - GEN_SIZE_PENALTY*individual.genome_size\n",
    "\n",
    "\n",
    "def statistics(population: list) -> tuple:\n",
    "    # mean fitness, best fitness, std dev of fitness\n",
    "    pop_fitness = [i.fitness for i in population]\n",
    "    best = max(population, key=lambda p: p.fitness)\n",
    "    return mean(pop_fitness), best.fitness, stdev(pop_fitness)\n",
    "\n",
    "\n",
    "def stochastic_universal_sampling(parents: list, sel_prob: list):\n",
    "    if OFFSPR_NUM >= len(parents):\n",
    "        return parents\n",
    "    mating_pool = list()\n",
    "    a = list(accumulate(sel_prob, func=operator.add))\n",
    "    cur_member = 0\n",
    "    i = 0\n",
    "    r = random.uniform(0, 1/OFFSPR_NUM)\n",
    "    while cur_member < OFFSPR_NUM:\n",
    "        while r <= a[i]:\n",
    "            mating_pool.append(parents[i])\n",
    "            r += 1/OFFSPR_NUM\n",
    "            cur_member += 1\n",
    "        i += 1\n",
    "    return mating_pool\n",
    "\n",
    "\n",
    "def parent_selection(population: list, s: float = 1.5) -> list:\n",
    "    population.sort(key=lambda g: g.fitness)\n",
    "    mu = len(population)\n",
    "    sel_prob = [(2-s)/mu + 2*r*(s-1)/(mu*(mu-1))\n",
    "                for r, g in enumerate(population)]\n",
    "    return stochastic_universal_sampling(population, sel_prob)\n",
    "\n",
    "\n",
    "def mutation(offsprings: list, heaps: Nim, k: int = 1) -> list:\n",
    "    mutants = list()\n",
    "    tau = k/sqrt(POP_SIZE)\n",
    "    for o in offsprings:\n",
    "        o.mutate(heaps.rows, tau)\n",
    "        o.fitness = fitness(o, heaps, FITNESS_STRATEGY)\n",
    "        mutants.append(o)\n",
    "    return mutants\n",
    "\n",
    "\n",
    "def crossover(parent_1: Genome, parent_2: Genome) -> tuple:\n",
    "    # arithmetic recombination for the following\n",
    "    c1_step_size = ALPHA_XOVER*parent_1.step_size + \\\n",
    "        (1-ALPHA_XOVER)*parent_2.step_size\n",
    "    c2_step_size = ALPHA_XOVER*parent_2.step_size + \\\n",
    "        (1-ALPHA_XOVER)*parent_1.step_size\n",
    "\n",
    "    c1_mutation_rate = ALPHA_XOVER*parent_1.mutation_rate + \\\n",
    "        (1-ALPHA_XOVER)*parent_2.mutation_rate\n",
    "    c2_mutation_rate = ALPHA_XOVER*parent_2.mutation_rate + \\\n",
    "        (1-ALPHA_XOVER)*parent_1.mutation_rate\n",
    "\n",
    "    c1_genome_size = int(ALPHA_XOVER*parent_1.genome_size +\n",
    "                         (1-ALPHA_XOVER)*parent_2.genome_size)\n",
    "    c2_genome_size = int(ALPHA_XOVER*parent_2.genome_size +\n",
    "                         (1-ALPHA_XOVER)*parent_1.genome_size)\n",
    "\n",
    "    # find the shorter parent and the longer parent\n",
    "    if parent_1.genome_size >= parent_2.genome_size:\n",
    "        long_p = parent_1\n",
    "        short_p = parent_2\n",
    "    else:\n",
    "        long_p = parent_2\n",
    "        short_p = parent_1\n",
    "\n",
    "    c1_conditions = list()\n",
    "    c2_conditions = list()\n",
    "    c1_actions = list()\n",
    "    c2_actions = list()\n",
    "\n",
    "    # fill the short parent with the elements of the long parent\n",
    "    for i in range(short_p.genome_size, long_p.genome_size):\n",
    "        short_p.conditions.append(long_p.conditions[i])\n",
    "        short_p.actions.append(long_p.actions[i])\n",
    "\n",
    "    # uniform crossover\n",
    "    for i, cond1, cond2, act1, act2 in zip(range(c1_genome_size), short_p.conditions, long_p.conditions, short_p.actions, long_p.actions):\n",
    "        r = random.random()\n",
    "        if r < 0.5:\n",
    "            c1_conditions.append(cond1)\n",
    "            c1_actions.append(act1)\n",
    "        else:\n",
    "            c1_conditions.append(cond2)\n",
    "            c1_actions.append(act2)\n",
    "\n",
    "    for i, cond1, cond2, act1, act2 in zip(range(c2_genome_size), short_p.conditions, long_p.conditions, short_p.actions, long_p.actions):\n",
    "        r = random.random()\n",
    "        if r < 0.5:\n",
    "            c2_conditions.append(cond1)\n",
    "            c2_actions.append(act1)\n",
    "        else:\n",
    "            c2_conditions.append(cond2)\n",
    "            c2_actions.append(act2)\n",
    "\n",
    "    assert len(c1_conditions) == c1_genome_size and len(\n",
    "        c1_actions) == c1_genome_size\n",
    "    assert len(c2_conditions) == c2_genome_size and len(\n",
    "        c2_actions) == c2_genome_size\n",
    "\n",
    "    # make the childs\n",
    "    c1 = Genome(c1_conditions, c1_actions, c1_genome_size,\n",
    "                c1_step_size, c1_mutation_rate, None)\n",
    "    c2 = Genome(c2_conditions, c2_actions, c2_genome_size,\n",
    "                c2_step_size, c2_mutation_rate, None)\n",
    "\n",
    "    return c1, c2\n",
    "\n",
    "\n",
    "def recombination(mating_pool: list, offspr_num: int) -> list:\n",
    "    offsprings = list()\n",
    "    for _ in range(int(offspr_num/2)):\n",
    "        p1, p2 = tuple(random.choices(mating_pool, k=2))\n",
    "        c1, c2 = crossover(p1, p2)\n",
    "        offsprings.append(c1)\n",
    "        offsprings.append(c2)\n",
    "    return offsprings\n",
    "\n",
    "\n",
    "def survivor_selection(population: list, offsprings: list) -> list:\n",
    "    # (μ, λ) selection + elitism\n",
    "    # gather the elites\n",
    "    elite_fitness = max(population, key=lambda g: g.fitness).fitness\n",
    "    elites = [g for g in population if isclose(\n",
    "        g.fitness, elite_fitness, abs_tol=5e-2)]\n",
    "    offsprings = offsprings + elites\n",
    "    # sort in decreasing order of fitness\n",
    "    offsprings.sort(key=lambda o: o.fitness, reverse=True)\n",
    "    return offsprings[0:POP_SIZE]  # return only the fittest\n",
    "\n",
    "\n",
    "def plot_stats(stats: list):\n",
    "    g = list(range(int(len(stats))))\n",
    "    mean_fitness = [v[0] for v in stats]\n",
    "    best_fitness = [v[1] for v in stats]\n",
    "    stddev_fitness = [v[2] for v in stats]\n",
    "    plt.figure()\n",
    "    plt.plot(g, mean_fitness, label=\"mean fitness\")\n",
    "    plt.plot(g, best_fitness, label=\"best fitness\")\n",
    "    plt.plot(g, stddev_fitness, label=\"std dev fitness\")\n",
    "    plt.xlim((0, len(stats)))\n",
    "    plt.xlabel(\"generation\")\n",
    "    plt.ylabel(\"fitness\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def extinction(population: list, heaps: Nim) -> list:\n",
    "    survivors = random.choices(population, k=int(POP_SIZE*SURVIVOR_FRAC))\n",
    "    offsprings = mutation(recombination(\n",
    "        survivors, POP_SIZE-len(survivors)), heaps)\n",
    "    for o in offsprings:\n",
    "        o.fitness = fitness(o, heaps, FITNESS_STRATEGY)\n",
    "        survivors.append(o)\n",
    "    logging.info(f\"Extinction event\")\n",
    "    return survivors\n",
    "\n",
    "\n",
    "def convergence(mean_fitness: list, num_gen: int = 3) -> bool:\n",
    "    if len(mean_fitness) <= num_gen + 1:\n",
    "        return False\n",
    "    # consider the last num_gen + 1 generations\n",
    "    eval_data = mean_fitness[-(num_gen+1):]\n",
    "    fitness_incr = [(eval_data[i]-eval_data[i-1])\n",
    "                    for i in range(len(eval_data)-1, 0, -1)]\n",
    "    lower_than_thresh = [f for f in fitness_incr if f < CONVERGENCE_THRESHOLD]\n",
    "    if len(lower_than_thresh) >= num_gen:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def evolve_nim_strategy(heaps: Nim) -> list:\n",
    "    stats = list()\n",
    "    population = initialization(\n",
    "        POP_SIZE, heaps)\n",
    "    stats.append(statistics(population))\n",
    "    if EXT_CNT is not None:\n",
    "        extinction_counter = EXT_CNT\n",
    "    else:\n",
    "        extinction_counter = GENERATIONS\n",
    "    logging.info(\n",
    "        f\"Generation {0}, fitness: mean = {stats[-1][0]}, best = {stats[-1][1]}, stddev = {stats[-1][2]}\")\n",
    "\n",
    "    gens = 0\n",
    "    while not termination_condition(gens, stats):\n",
    "        # this to allow an extinction to happen, you also need convergence\n",
    "        extinction_counter -= 1\n",
    "\n",
    "        # extinction routine\n",
    "        # this to avoid an exinction too close to the end of the run\n",
    "        if EXT_CNT is not None and GENERATIONS - gens > EXT_CNT and extinction_counter == 0:\n",
    "            mean_fitness = [f[0] for f in stats]\n",
    "            # see if the mean fitness did converge in the last gens\n",
    "            if convergence(mean_fitness):\n",
    "                population = extinction(\n",
    "                    population, heaps)\n",
    "                extinction_counter = EXT_CNT\n",
    "\n",
    "        # niching for diversity\n",
    "        if NICHES is not None and NICHES > 1:\n",
    "            for n in range(NICHES):\n",
    "                niche = [(i, g)\n",
    "                         for i, g in enumerate(population) if i % NICHES == n]\n",
    "                niche_pop = [t[1] for t in niche]\n",
    "                niche_idx = [t[0] for t in niche]\n",
    "\n",
    "                parents = parent_selection(niche_pop, int(OFFSPR_NUM/NICHES))\n",
    "                offsprings = mutation(recombination(\n",
    "                    parents, int(OFFSPR_NUM/NICHES)), heaps)\n",
    "                niche_pop = survivor_selection(\n",
    "                    niche_pop, offsprings)\n",
    "\n",
    "                # put the niche back into the population\n",
    "                for i, g in zip(niche_idx, niche_pop):\n",
    "                    population[i] = g\n",
    "\n",
    "                # migration: just swap two elements in population\n",
    "                num_migrants = int(MIGRANT_FRAC*POP_SIZE)\n",
    "                exchange_niche = random.randint(0, NICHES-1)\n",
    "\n",
    "                imm_candidates = [(i, g) for i, g in enumerate(\n",
    "                    population) if i % NICHES == exchange_niche]\n",
    "                immigrants = random.choices(imm_candidates, k=num_migrants)\n",
    "                em_candidates = [(i, g) for i, g in enumerate(\n",
    "                    population) if i % NICHES == n]\n",
    "                emigrants = random.choices(em_candidates, k=num_migrants)\n",
    "\n",
    "                for em, im in zip(emigrants, immigrants):\n",
    "                    population[em[0]] = im[1]\n",
    "                    population[im[0]] = em[1]\n",
    "\n",
    "        else:\n",
    "            # whole population, no niching\n",
    "            parents = parent_selection(population)\n",
    "            offsprings = mutation(recombination(\n",
    "                parents, OFFSPR_NUM), heaps)\n",
    "            population = survivor_selection(population, offsprings)\n",
    "\n",
    "        # compute this generation statistics\n",
    "        stats.append(statistics(population))\n",
    "        logging.info(\n",
    "            f\"Generation {gens+1}, fitness: mean = {stats[-1][0]}, best = {stats[-1][1]}, stddev = {stats[-1][2]}\")\n",
    "\n",
    "        # increase generations counter\n",
    "        gens += 1\n",
    "\n",
    "    plot_stats(stats)\n",
    "    solutions = [g for g in population if isclose(\n",
    "        g.fitness, MAX_BEST_FITNESS, abs_tol=0.05)]\n",
    "\n",
    "    return solutions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Generation 0, fitness: mean = 0.0052, best = 0.18, stddev = 0.021058178786105296\n",
      "INFO:root:Generation 1, fitness: mean = 0.02744, best = 0.32, stddev = 0.04604874998031433\n",
      "INFO:root:Generation 2, fitness: mean = 0.05854, best = 0.32, stddev = 0.051898509714839045\n",
      "INFO:root:Generation 3, fitness: mean = 0.09522, best = 0.32, stddev = 0.044794695327225055\n",
      "INFO:root:Generation 4, fitness: mean = 0.12238, best = 0.32, stddev = 0.0458993365768656\n",
      "INFO:root:Generation 5, fitness: mean = 0.15448, best = 0.32, stddev = 0.04744715022135952\n",
      "INFO:root:Generation 6, fitness: mean = 0.19106, best = 0.34, stddev = 0.05066567300294829\n",
      "INFO:root:Generation 7, fitness: mean = 0.22758, best = 0.37, stddev = 0.04607156148379508\n",
      "INFO:root:Generation 8, fitness: mean = 0.25784, best = 0.39, stddev = 0.0453281776313007\n",
      "INFO:root:Generation 9, fitness: mean = 0.28622, best = 0.49, stddev = 0.0496189043746704\n",
      "INFO:root:Generation 10, fitness: mean = 0.30676, best = 0.54, stddev = 0.046646051367896436\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice won 37 times\n",
      "Bob won 63 times\n"
     ]
    }
   ],
   "source": [
    "heaps = Nim(N_HEAPS)\n",
    "solutions = evolve_nim_strategy(heaps)\n",
    "\n",
    "# test on a match against a nim-sum strategy\n",
    "solution = random.choice(solutions)\n",
    "Alice = EvolutionalPlayer(\"Alice\", solution, evolved_strategy)\n",
    "Bob = Player(\"Bob\", nim_sum_strategy)\n",
    "winners = match(Alice, Bob, heaps, N_GAMES)\n",
    "print_match_result(Alice, Bob, winners)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task3.3 MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameNode:\n",
    "    def __init__(self, state: list, parent=None, children: list = None):\n",
    "        self._state = state\n",
    "        self._parent = parent\n",
    "        self._children = children\n",
    "        self._value = 0\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(bytes(self._state))\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        return self._value\n",
    "\n",
    "    @value.setter\n",
    "    def value(self, val):\n",
    "        self._value = val\n",
    "\n",
    "    @property\n",
    "    def parent(self):\n",
    "        return self._parent\n",
    "\n",
    "    @parent.setter\n",
    "    def parent(self, val):\n",
    "        self._parent = val\n",
    "\n",
    "    @property\n",
    "    def children(self):\n",
    "        return self._children\n",
    "\n",
    "    def add_child(self, child):\n",
    "        self._children.append(child)\n",
    "\n",
    "    @property\n",
    "    def state(self):\n",
    "        return self._state\n",
    "\n",
    "\n",
    "def heuristic(node: GameNode, hash_table: dict):\n",
    "    # check if the value of the state has been already computed\n",
    "    h = hash_table.get(node)\n",
    "    if h is None:\n",
    "        code = check_critical_situations(node.state)\n",
    "        if code > 0:\n",
    "            h = float('inf')\n",
    "        elif code < 0:\n",
    "            h = -float('inf')\n",
    "        else:\n",
    "            if nim_sum(node.state) == 0:  # bad state, gotta do a random action\n",
    "                h = -1\n",
    "            else:\n",
    "                h = 1   # can reduce the nim-sum to zero\n",
    "        hash_table[node] = h  # insert in hash_table for later use\n",
    "    return h\n",
    "\n",
    "\n",
    "def minmax(node: GameNode, depth: int, maximising: bool, hash_table: dict):\n",
    "    if depth == 0:\n",
    "        # if the node is a terminal state like [0, 0, 0]\n",
    "        if sum(node.state) == 0:\n",
    "            if maximising:\n",
    "                # i won because the opponent had like [0, 1, 0] and it took the last object\n",
    "                node.value = float('inf')\n",
    "            else:\n",
    "                node.value = -float('inf')  # i lost\n",
    "        else:\n",
    "            node.value = heuristic(node, hash_table)\n",
    "        return node.value\n",
    "    if maximising:\n",
    "        node.value = -float('inf')\n",
    "        for c in node.children:\n",
    "            node.value = max(node.value, minmax(c, depth-1, False, hash_table))\n",
    "        return node.value\n",
    "    else:\n",
    "        node.value = float('inf')\n",
    "        for c in node.children:\n",
    "            node.value = min(node.value, minmax(c, depth-1, True, hash_table))\n",
    "        return node.value\n",
    "\n",
    "\n",
    "def game_tree(state: list, parent: GameNode, depth: int) -> GameNode:\n",
    "    this_node = GameNode(state, parent, list())\n",
    "    if depth > 0:\n",
    "        for i in range(len(state)):\n",
    "            # list all the possible new sizes of the heap state[i]\n",
    "            for j in range(state[i]):\n",
    "                child_state = copy.deepcopy(state)\n",
    "                child_state[i] = j\n",
    "                this_node.add_child(game_tree(child_state, this_node, depth-1))\n",
    "    return this_node\n",
    "\n",
    "\n",
    "class MinMaxPlayer(Player):\n",
    "    def __init__(self, name, strategy, look_ahead):\n",
    "        super().__init__(name, strategy)\n",
    "        self._hash_table = {}\n",
    "        self._look_ahead = look_ahead\n",
    "\n",
    "    def flush_parameters(self):\n",
    "        self._hash_table = {}\n",
    "        super().flush_parameters()\n",
    "\n",
    "    @property\n",
    "    def hash_table(self):\n",
    "        return self._hash_table\n",
    "\n",
    "    @property\n",
    "    def look_ahead(self):\n",
    "        return self._look_ahead\n",
    "\n",
    "\n",
    "def minmax_strategy(player: MinMaxPlayer, heaps: Nim):\n",
    "    depth = player.look_ahead*2  # depth of the tree is the double of plies look ahead\n",
    "\n",
    "    # generate game tree, access it through the root\n",
    "    root = game_tree(heaps.rows, None, depth)\n",
    "\n",
    "    # apply minmax algorithm, return the heuristic value of the action to be taken\n",
    "    chosen_value = minmax(root, depth, True, player.hash_table)\n",
    "\n",
    "    # select actions\n",
    "    viable_children_idxs = [i for i, c in enumerate(\n",
    "        root.children) if c.value == chosen_value]\n",
    "    chosen_child_idx = random.choice(viable_children_idxs)\n",
    "    chosen_child = root.children[chosen_child_idx]\n",
    "\n",
    "    # compute the heap idx and the number of object to take\n",
    "    difference = [i-j for i, j in zip(root.state, chosen_child.state)]\n",
    "    num_objects = max(difference)\n",
    "    chosen_heap = difference.index(num_objects)\n",
    "\n",
    "    # nim the heap\n",
    "    heaps.nimming(chosen_heap, num_objects, player)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice won 88 times\n",
      "Bob won 12 times\n"
     ]
    }
   ],
   "source": [
    "# minmax vs random\n",
    "heaps = Nim(N_HEAPS)\n",
    "Alice = MinMaxPlayer(\"Alice\", minmax_strategy, 1)\n",
    "Bob = Player(\"Bob\", random_strategy)\n",
    "winners = match(Alice, Bob, heaps, N_GAMES)\n",
    "print_match_result(Alice, Bob, winners)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice won 54 times\n",
      "Bob won 46 times\n"
     ]
    }
   ],
   "source": [
    "# minmax vs minmax\n",
    "heaps = Nim(N_HEAPS)\n",
    "Alice = MinMaxPlayer(\"Alice\", minmax_strategy, 1)\n",
    "Bob = MinMaxPlayer(\"Bob\", minmax_strategy, 1)\n",
    "winners = match(Alice, Bob, heaps, N_GAMES)\n",
    "print_match_result(Alice, Bob, winners)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice won 35 times\n",
      "Bob won 65 times\n"
     ]
    }
   ],
   "source": [
    "# minmax vs nimsum\n",
    "heaps = Nim(N_HEAPS)\n",
    "Alice = MinMaxPlayer(\"Alice\", minmax_strategy, 1)\n",
    "Bob = Player(\"Bob\", nim_sum_strategy)\n",
    "winners = match(Alice, Bob, heaps, N_GAMES)\n",
    "print_match_result(Alice, Bob, winners)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Task3.4 Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES = 500\n",
    "PRINT_RATIO = 0.1\n",
    "OPP_STRATEGY = random_strategy\n",
    "MAX_LEARNING_RATE = 1\n",
    "EXPLORATION_RATE = 0.1\n",
    "MAX_REWARD = 1\n",
    "DISCOUNT_FACT = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Action = namedtuple(\"Action\", \"heap quantity\")\n",
    "\n",
    "\n",
    "class RLAgent(Player):\n",
    "    def __init__(self, name: str, explore: bool):\n",
    "        super().__init__(name, rl_strategy)\n",
    "        self._explore = explore\n",
    "        self._Q_table = dict()\n",
    "        self._frequencies = dict()\n",
    "        self._previous_state = None\n",
    "        self._previous_action = None\n",
    "\n",
    "    @property\n",
    "    def Q_table(self):\n",
    "        return self._Q_table\n",
    "\n",
    "    def reward(self, state: tuple, current: bool) -> float:\n",
    "        return 0\n",
    "        # # next state is [0,1,0, ..., 0] a losing state for the OPPONENT (leads to the terminal state [0, ..., 0])\n",
    "        # if current and sum(state) == 1:\n",
    "        #     return MAX_REWARD\n",
    "        # # next state is [0, 0, ..., 0], losing (terminal) state for the AGENT\n",
    "        # elif current and sum(state) == 0:\n",
    "        #     return -MAX_REWARD\n",
    "        # else:\n",
    "        #     return 0 # next state is not right before a terminal state\n",
    "\n",
    "    def generate_actions(self, cur_state: tuple) -> list:\n",
    "        cur_actions = list()\n",
    "        for heap_idx, heap_size in enumerate(cur_state): # loop for each heap...\n",
    "            for q in range(1, heap_size+1): # ... and for each possible quantity to be taken off\n",
    "\n",
    "                assert q > 0 and q <= heap_size # check that the quantity is legal\n",
    "\n",
    "                a = Action(heap_idx, q) # create an Action\n",
    "                cur_actions.append(a) # add it to the list of legal actions\n",
    "\n",
    "                # the current state is not in the Q-table add it\n",
    "                if cur_state not in self._Q_table:\n",
    "                    self._Q_table[cur_state] = dict()\n",
    "                    self._frequencies[cur_state] = dict()\n",
    "                \n",
    "                # if the action for the current state is not in the Q-table add it\n",
    "                if a not in self._Q_table[cur_state]:\n",
    "                    self._Q_table[cur_state][a] = self.reward(cur_state, True) # compute its reward\n",
    "                    self._frequencies[cur_state][a] = 0 # set its frequency to zero\n",
    "\n",
    "        return cur_actions\n",
    "\n",
    "    def learning_rate(self) -> float:\n",
    "        return MAX_LEARNING_RATE*1/(self._frequencies[self._previous_state][self._previous_action]+1)\n",
    "\n",
    "    def exploration_function(self, state: tuple) -> Action:\n",
    "        r = random.random()\n",
    "        if self._explore and r < EXPLORATION_RATE:  # exploration: choose the action less frequently chosen\n",
    "            action_freqs = [(a, f)\n",
    "                            for a, f in self._frequencies[state].items()]\n",
    "            action_freqs.sort(key=lambda v: v[1])\n",
    "            return action_freqs.pop(0)[0]\n",
    "        else:  # exploitation: choose the action with the highest Q-value\n",
    "            action_Qvals = [(a, q) for a, q in self._Q_table[state].items()]\n",
    "            action_Qvals.sort(key=lambda v: v[1], reverse=True)\n",
    "            return action_Qvals.pop(0)[0]\n",
    "\n",
    "    def policy(self, current_state: Nim):\n",
    "        cur_state = tuple(current_state.rows)\n",
    "\n",
    "        assert cur_state is not None\n",
    "        assert sum(cur_state) > 0\n",
    "        assert cur_state != self._previous_state\n",
    "\n",
    "        # generate legal actions from cur_state\n",
    "        cur_actions = self.generate_actions(cur_state)\n",
    "\n",
    "        # update previous state\n",
    "        if self._previous_state is not None and self._previous_action is not None:\n",
    "            self._frequencies[self._previous_state][self._previous_action] += 1\n",
    "\n",
    "            max_cur_state_Q_val = max(self._Q_table[cur_state].values())\n",
    "            prev_state_Q_val = self._Q_table[self._previous_state][self._previous_action]\n",
    "\n",
    "            self._Q_table[self._previous_state][self._previous_action] += self.learning_rate()*(\n",
    "                self.reward(self._previous_state, current=False) + DISCOUNT_FACT*max_cur_state_Q_val - prev_state_Q_val)\n",
    "\n",
    "        # choose action\n",
    "        selected_action = self.exploration_function(cur_state)\n",
    "\n",
    "        current_state.nimming(selected_action.heap, selected_action.quantity, self)\n",
    "\n",
    "        self._previous_state = cur_state\n",
    "        self._previous_action = selected_action\n",
    "\n",
    "    def flush_parameters(self) -> None:\n",
    "        self._previous_action = None\n",
    "        self._previous_state = None\n",
    "        super().flush_parameters()\n",
    "\n",
    "    @property\n",
    "    def explore(self):\n",
    "        return self._explore\n",
    "\n",
    "    @explore.setter\n",
    "    def explore(self, val):\n",
    "        self._explore = val\n",
    "\n",
    "    def update(self, won:bool) -> None:\n",
    "        if won:\n",
    "            self._Q_table[self._previous_state][self._previous_action] = MAX_REWARD\n",
    "        else:\n",
    "            self._Q_table[self._previous_state][self._previous_action] = MAX_REWARD\n",
    "\n",
    "\n",
    "# just a wrapper to make it works with the previous functions\n",
    "def rl_strategy(agent: RLAgent, state: Nim):\n",
    "    agent.policy(state)\n",
    "\n",
    "\n",
    "def reinforcement_learning(heaps: Nim, agent_name: str) -> RLAgent:\n",
    "    agent = RLAgent(agent_name, explore=True)\n",
    "    opp = Player(\"opp\", OPP_STRATEGY)\n",
    "    for e in range(EPISODES):\n",
    "        # returns a list of tuples (winner_name:str, n_plies:int), but here we have only one game\n",
    "        winner = match(agent, opp, heaps, n_games=1)[0] \n",
    "        \n",
    "        # update final state, action Q-values with the reward\n",
    "        if winner[0] == agent_name: \n",
    "            agent.update(won=True)\n",
    "        else:\n",
    "            agent.update(won=False)\n",
    "        \n",
    "        # print infos\n",
    "        if e % int(PRINT_RATIO*EPISODES) == 0 and tuple(heaps.rows) in agent.Q_table:\n",
    "            init_state_utility = max([v for a, v in agent.Q_table[tuple(heaps.rows)]]) # U(s) = max Q(s, a), for each a in A(s)\n",
    "            logging.info(f\"episode: {e}, utility for initial state: {init_state_utility}\") \n",
    "\n",
    "    return agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:episode: 0, utility for initial state: 5\n",
      "INFO:root:episode: 50, utility for initial state: 5\n",
      "INFO:root:episode: 100, utility for initial state: 5\n",
      "INFO:root:episode: 150, utility for initial state: 5\n",
      "INFO:root:episode: 200, utility for initial state: 5\n",
      "INFO:root:episode: 250, utility for initial state: 5\n",
      "INFO:root:episode: 300, utility for initial state: 5\n",
      "INFO:root:episode: 350, utility for initial state: 5\n",
      "INFO:root:episode: 400, utility for initial state: 5\n",
      "INFO:root:episode: 450, utility for initial state: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice won 87 times\n",
      "Bob won 13 times\n"
     ]
    }
   ],
   "source": [
    "heaps = Nim(N_HEAPS)\n",
    "Alice = reinforcement_learning(heaps, \"Alice\")\n",
    "Alice.explore = False\n",
    "Bob = Player(\"Bob\", random_strategy)\n",
    "winners = match(Alice, Bob, heaps, N_GAMES)\n",
    "print_match_result(Alice, Bob, winners)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "9736098bae0344245c3be8054c814b256168eeaa5b252fe2e1e318181a993fce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
