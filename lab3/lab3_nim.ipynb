{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright **`(c)`** 2022 Giovanni Squillero `<squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Lab 3: Policy Search\n",
    "\n",
    "## Task\n",
    "\n",
    "Write agents able to play [*Nim*](https://en.wikipedia.org/wiki/Nim), with an arbitrary number of rows and an upper bound $k$ on the number of objects that can be removed in a turn (a.k.a., *subtraction game*).\n",
    "\n",
    "The goal of the game is to **avoid** taking the last object.\n",
    "\n",
    "* Task3.1: An agent using fixed rules based on *nim-sum* (i.e., an *expert system*)\n",
    "* Task3.2: An agent using evolved rules\n",
    "* Task3.3: An agent using minmax\n",
    "* Task3.4: An agent using reinforcement learning\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Create the directory `lab3` inside the course repo \n",
    "* Put a `README.md` and your solution (all the files, code and auxiliary data if needed)\n",
    "\n",
    "## Notes\n",
    "\n",
    "* Working in group is not only allowed, but recommended (see: [Ubuntu](https://en.wikipedia.org/wiki/Ubuntu_philosophy) and [Cooperative Learning](https://files.eric.ed.gov/fulltext/EJ1096789.pdf)). Collaborations must be explicitly declared in the `README.md`.\n",
    "* [Yanking](https://www.emacswiki.org/emacs/KillingAndYanking) from the internet is allowed, but sources must be explicitly declared in the `README.md`.\n",
    "\n",
    "**Deadline**\n",
    "\n",
    "T.b.d.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "import copy\n",
    "from math import sqrt, exp, isclose\n",
    "from typing import Callable\n",
    "from collections import namedtuple\n",
    "from itertools import accumulate\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import stdev, mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_HEAPS = 5\n",
    "N_GAMES = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "random.seed(13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, name: str, strategy: Callable, *strategy_args):\n",
    "        self._strategy = strategy\n",
    "        self._strategy_args = strategy_args\n",
    "        self._name = name\n",
    "        self._loser = False\n",
    "        self._n_plies = 0\n",
    "\n",
    "    def ply(self, state):\n",
    "        self._strategy(self, state, *self._strategy_args)\n",
    "        self._n_plies += 1\n",
    "\n",
    "    @property\n",
    "    def loser(self):\n",
    "        return self._loser\n",
    "\n",
    "    @loser.setter\n",
    "    def loser(self, val):\n",
    "        self._loser = val\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "\n",
    "    @property\n",
    "    def n_plies(self):\n",
    "        return self._n_plies\n",
    "\n",
    "    @n_plies.setter\n",
    "    def n_plies(self, val):\n",
    "        self._n_plies = val\n",
    "\n",
    "    def flush_parameters(self):\n",
    "        self._n_plies = 0\n",
    "        self._loser = False\n",
    "\n",
    "\n",
    "class Nim:\n",
    "    def __init__(self, num_rows: int = None, rows: list = None, k: int = None) -> None:\n",
    "        if num_rows is not None:\n",
    "            self._rows = [i*2 + 1 for i in range(num_rows)]\n",
    "        else:\n",
    "            self._rows = rows\n",
    "        self._k = k\n",
    "\n",
    "    def nimming(self, row: int, num_objects: int, player: Player) -> None:\n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert self._k is None or num_objects <= self._k\n",
    "        logging.debug(f\"Heaps at player {player.name} turn: {self._rows}\")\n",
    "        logging.debug(\n",
    "            f\"Player {player.name} takes {num_objects} from heap {row}\")\n",
    "        self._rows[row] -= num_objects\n",
    "        if sum(self._rows) == 0:\n",
    "            player.loser = True\n",
    "\n",
    "    @property\n",
    "    def rows(self):\n",
    "        return self._rows\n",
    "\n",
    "    def copy(self):\n",
    "        return copy.deepcopy(self)\n",
    "\n",
    "\n",
    "def play(A: Player, B: Player, state: Nim) -> Player:\n",
    "    while not (A.loser or B.loser):\n",
    "        A.ply(state)\n",
    "        if not A.loser:\n",
    "            B.ply(state)\n",
    "    if A.loser:\n",
    "        return B\n",
    "    elif B.loser:\n",
    "        return A\n",
    "\n",
    "\n",
    "def match(A: Player, B: Player, state: Nim, n_games: int):\n",
    "    winners = list()\n",
    "    for i in range(n_games):\n",
    "        initial_state = state.copy()\n",
    "        A.flush_parameters()\n",
    "        B.flush_parameters()\n",
    "        r = random.random()\n",
    "        if r <= 0.5:\n",
    "            w = play(A, B, initial_state)\n",
    "        else:\n",
    "            w = play(B, A, initial_state)\n",
    "        winners.append((w.name, w.n_plies))\n",
    "    return winners\n",
    "\n",
    "\n",
    "def print_match_result(A: Player, B: Player, res: list):\n",
    "    n_A_win = 0\n",
    "    n_games = len(res)\n",
    "    for i in range(n_games):\n",
    "        if res[i][0] == A.name:\n",
    "            n_A_win += 1\n",
    "    print(f\"{A.name} won {n_A_win} times\\n{B.name} won {n_games - n_A_win} times\")\n",
    "\n",
    "\n",
    "def random_strategy(player: Player, heaps: Nim, decrement: bool = False):\n",
    "    non_zero_heaps_idxs = [i for i, v in enumerate(\n",
    "        heaps.rows) if v > 0]  # choose a random non-zero heap\n",
    "    idx_heap = random.choice(non_zero_heaps_idxs)\n",
    "    if decrement:\n",
    "        quantity = 1\n",
    "    else:\n",
    "        # decrease it of a random quantity\n",
    "        quantity = random.randint(1, heaps.rows[idx_heap])\n",
    "    heaps.nimming(idx_heap, quantity, player)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task3.1 Nim-Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nim_sum(l: list):\n",
    "    sum = 0\n",
    "    for _, v in enumerate(l):\n",
    "        sum ^= v\n",
    "    return sum\n",
    "\n",
    "\n",
    "def check_critical_situations(heaps: list) -> int:\n",
    "    n_heaps = len(heaps)\n",
    "    n_heaps_to_zero = len([i for i, h in enumerate(heaps) if h == 0])\n",
    "    n_heaps_to_one = len([i for i, h in enumerate(heaps) if h == 1])\n",
    "    n_heaps_greater_than_zero = n_heaps - n_heaps_to_zero\n",
    "    n_heaps_greater_than_one = n_heaps_greater_than_zero - n_heaps_to_one\n",
    "\n",
    "    # [1, a, 1, 1, 0, 0], a > 1\n",
    "    if n_heaps_greater_than_zero % 2 == 0 and n_heaps_greater_than_one == 1:\n",
    "        return 1\n",
    "    # [1, a, 1, 0, 0], a > 1\n",
    "    if n_heaps_greater_than_zero % 2 == 1 and n_heaps_greater_than_one == 1:\n",
    "        return 2\n",
    "    # [a, 0, 0], a > 1\n",
    "    if n_heaps_greater_than_one == 1 and n_heaps_to_one == 0:\n",
    "        return 3\n",
    "    # [1, 1, 1, 1, 0, ..., 0] no need to manage this explicitly\n",
    "    if n_heaps_to_one % 2 == 0 and n_heaps_to_zero + n_heaps_to_one == n_heaps:\n",
    "        return 4\n",
    "    # [0, 0, ..., 0] the player has won\n",
    "    if n_heaps_to_zero == n_heaps:\n",
    "        return 5\n",
    "    # [1, 1, 1, 0, ..., 0]\n",
    "    if n_heaps_to_one % 2 == 1 and n_heaps_to_zero + n_heaps_to_one == n_heaps:\n",
    "        return -1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def critical_situations(player: Player, heaps: Nim) -> bool:\n",
    "\n",
    "    code = check_critical_situations(heaps.rows)\n",
    "\n",
    "    if code != 0:\n",
    "        if code == 1:  # [1, a, 1, 1, 0, 0], a > 1\n",
    "            # take all objects from the heap with more than 1 object\n",
    "            heaps.nimming(heaps.rows.index(max(heaps.rows)),\n",
    "                          max(heaps.rows), player)\n",
    "        elif code == 2:  # [1, a, 1, 0, 0], a > 1\n",
    "            # take all objects but 1 from the heap with more than 1 object\n",
    "            heaps.nimming(heaps.rows.index(max(heaps.rows)),\n",
    "                          max(heaps.rows)-1, player)\n",
    "        elif code == 3:  # [a, 0, 0], a > 1\n",
    "            # take all objects but 1 from the last non zero heap with more than 1 object\n",
    "            heaps.nimming(heaps.rows.index(max(heaps.rows)),\n",
    "                          max(heaps.rows)-1, player)\n",
    "        # [1, 1, 0, ..., 0] or [1, 1, 1, 0, ..., 0]\n",
    "        elif code == 4 or code == -1:\n",
    "            # take from the first non zero heap\n",
    "            heaps.nimming(heaps.rows.index(1), 1, player)\n",
    "        elif code == 5:\n",
    "            pass\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def nim_sum_strategy(player: Player, heaps: Nim):\n",
    "    if sum(heaps.rows) == 0:\n",
    "        raise Exception(\"There is no heap left!\")\n",
    "\n",
    "    logging.debug(\n",
    "        f\"Player: {player.name}, heaps nim-sum: {nim_sum(heaps.rows)}\")\n",
    "\n",
    "    if not critical_situations(player, heaps):\n",
    "        # normal game\n",
    "        x = nim_sum(heaps.rows)\n",
    "        y = [nim_sum([x, h]) for _, h in enumerate(heaps.rows)]\n",
    "        winning_heaps = [i for i, h in enumerate(heaps.rows) if y[i] < h]\n",
    "        if len(winning_heaps) > 0:  # if there's a winning heap\n",
    "            chosen_heap_idx = random.choice(winning_heaps)\n",
    "            quantity = heaps.rows[chosen_heap_idx]-y[chosen_heap_idx]\n",
    "            heaps.nimming(chosen_heap_idx, quantity, player)\n",
    "        else:  # take from a random heap\n",
    "            random_strategy(player, heaps)\n",
    "\n",
    "    logging.debug(\n",
    "        f\"Heaps nim-sum after player {player.name} move: {nim_sum(heaps.rows)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice won 99 times\n",
      "Bob won 1 times\n"
     ]
    }
   ],
   "source": [
    "# trying nim-sum vs random strategy\n",
    "heaps = Nim(N_HEAPS)\n",
    "Alice = Player(\"Alice\", nim_sum_strategy)\n",
    "Bob = Player(\"Bob\", random_strategy)\n",
    "winners = match(Alice, Bob, heaps, N_GAMES)\n",
    "print_match_result(Alice, Bob, winners)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice won 58 times\n",
      "Bob won 42 times\n"
     ]
    }
   ],
   "source": [
    "# trying nim-sum vs nim-sum strategy\n",
    "heaps = Nim(N_HEAPS)\n",
    "Alice = Player(\"Alice\", nim_sum_strategy)\n",
    "Bob = Player(\"Bob\", nim_sum_strategy)\n",
    "winners = match(Alice, Bob, heaps, N_GAMES)\n",
    "print_match_result(Alice, Bob, winners)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task3.2 Evolved Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "GENERATIONS = 1_000\n",
    "POP_SIZE = 500\n",
    "OFFSPR_NUM = 5*POP_SIZE\n",
    "FITNESS_N_GAMES = N_GAMES  # number of games upon which to evaluate the fitness\n",
    "# act as a penalty to the fitness, to prefer smaller genomes (NOT ACTUALLY NEEDED)\n",
    "GEN_SIZE_PENALTY = 0\n",
    "SURVIVOR_FRAC = 0.2  # fraction on survivors after extinction\n",
    "EXT_CNT = 5  # number of generations after which an extinction can happen, None to deactivate extinction\n",
    "NICHES = 5  # number of niches, None to deactivate niches\n",
    "ALPHA_XOVER = 0.5  # how much of one parent to pass to the children in crossover\n",
    "# ratio between the max genome size and the number of heaps, used in initialization to roughly control genome size\n",
    "MAX_GEN_SIZE_RATIO_INIT = 100\n",
    "FITNESS_STRATEGY = nim_sum_strategy  # strategy used to train the algorithm\n",
    "MIGRANT_FRAC = 0.1  # fraction of migrants individual in niching\n",
    "# min increase of the mean fitness below which it is considered converged, if 1 is always converged, 0 is never\n",
    "CONVERGENCE_THRESHOLD = 0.01\n",
    "MAX_BEST_FITNESS = 0.5  # to avoid overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a condition is represented by a list of numbers + character '#' for don't care\n",
    "# with the following meaning: heaps[i] = condition[i] and heaps[i+] = condition[i+] and etc...\n",
    "# an action is represented by a tuple of two numbers: the heap index and\n",
    "# the quantity to be take from it.\n",
    "# the max size of the genome is the number of possible actions times the number of possible conditions\n",
    "# that is, if h(i) is the size of the i-th heap, (∏(h(i)+1)*∑h(i) for i=0, 1, ..., n-1\n",
    "# of course this does not scale, so the size of the genome will be an evolved parameter.\n",
    "\n",
    "class Genome:\n",
    "    def __init__(self, conditions: list, actions: list, genome_size: int, step_size: float, mutation_rate: float, fitness: float = None):\n",
    "        self._conditions = conditions\n",
    "        self._actions = actions\n",
    "        self._genome_size = genome_size\n",
    "        self._step_size = step_size\n",
    "        self._mutation_rate = mutation_rate\n",
    "        self._fitness = fitness\n",
    "\n",
    "    @property\n",
    "    def conditions(self):\n",
    "        return self._conditions\n",
    "\n",
    "    @property\n",
    "    def actions(self):\n",
    "        return self._actions\n",
    "\n",
    "    @property\n",
    "    def genome_size(self):\n",
    "        return self._genome_size\n",
    "\n",
    "    @property\n",
    "    def fitness(self):\n",
    "        return self._fitness\n",
    "\n",
    "    @fitness.setter\n",
    "    def fitness(self, val):\n",
    "        self._fitness = val\n",
    "\n",
    "    @property\n",
    "    def step_size(self):\n",
    "        return self._step_size\n",
    "\n",
    "    @property\n",
    "    def mutation_rate(self):\n",
    "        return self._mutation_rate\n",
    "\n",
    "    def check_conditions(self, heaps: list) -> tuple:\n",
    "        for i, cond in enumerate(self._conditions):\n",
    "            found = True\n",
    "            for j, v in enumerate(cond):\n",
    "                if heaps[j] != v and v != '#':\n",
    "                    found = False\n",
    "                    break\n",
    "            if found:\n",
    "                return self._actions[i]\n",
    "        return None\n",
    "\n",
    "    def mutate(self, heaps: list, tau: float) -> None:\n",
    "        # mutate step size\n",
    "        self._step_size = self._step_size*exp(tau*random.gauss(0, 1))\n",
    "\n",
    "        # mutate mutation rate\n",
    "        self._mutation_rate = self._mutation_rate + \\\n",
    "            self._step_size*random.gauss(0, 1)\n",
    "        if self._mutation_rate > 1:\n",
    "            self._mutation_rate = 1\n",
    "        elif self._mutation_rate < 0:\n",
    "            self._mutation_rate = 0\n",
    "\n",
    "        # mutate conditions\n",
    "        new_conditions = list()\n",
    "        for cond in self._conditions:\n",
    "            new_cond = list()\n",
    "            for i, c in enumerate(cond):\n",
    "                symbols = [h for h in range(1, heaps[i]+1)]\n",
    "                symbols.append('#')\n",
    "\n",
    "                r = random.random()\n",
    "                if r < self._mutation_rate:\n",
    "                    new_cond.append(random.choice(symbols))\n",
    "                else:\n",
    "                    new_cond.append(c)\n",
    "\n",
    "            new_conditions.append(new_cond)\n",
    "\n",
    "        # mutate actions\n",
    "        new_actions = list()\n",
    "        for act in self._actions:\n",
    "\n",
    "            # mutate the heap idx\n",
    "            r = random.random()\n",
    "            if r < self._mutation_rate:\n",
    "                heap_idx = random.randint(0, len(heaps)-1)\n",
    "            else:\n",
    "                heap_idx = act[0]\n",
    "\n",
    "            # mutate the quantity\n",
    "            max_q = heaps[heap_idx]\n",
    "            s = random.random()\n",
    "            if s < self._mutation_rate:\n",
    "                quant = random.randint(1, max_q)\n",
    "            else:\n",
    "                quant = act[1]\n",
    "\n",
    "            new_actions.append((heap_idx, quant))\n",
    "\n",
    "        # mutate genome size\n",
    "        old_genome_size = self._genome_size\n",
    "        self._genome_size = int(\n",
    "            self._genome_size + self._step_size*random.gauss(0, 1))\n",
    "        if self._genome_size <= 0:\n",
    "            self._genome_size = 1\n",
    "        diff = self._genome_size - old_genome_size\n",
    "\n",
    "        if diff < 0:\n",
    "            # pop elements until the right size\n",
    "            while diff != 0:\n",
    "                idx = random.choice(range(len(new_conditions)))\n",
    "                new_conditions.pop(idx)\n",
    "                new_actions.pop(idx)\n",
    "                diff += 1\n",
    "\n",
    "        elif diff > 0:\n",
    "            # fill in with random\n",
    "            for i in range(diff):\n",
    "                new_conditions.append(gen_random_condition(heaps))\n",
    "                new_actions.append(gen_random_action(heaps))\n",
    "\n",
    "        assert len(new_actions) == self._genome_size\n",
    "        assert len(new_conditions) == self._genome_size\n",
    "\n",
    "        # finally\n",
    "        self._conditions = new_conditions\n",
    "        self._actions = new_actions\n",
    "\n",
    "\n",
    "def gen_random_condition(heaps: list) -> list:\n",
    "    condition = list()\n",
    "    for i, heap in enumerate(heaps):  # for each heap\n",
    "        n = [h for h in range(1, heap + 1)]  # find the possible conditions\n",
    "        n.append('#')                       # add a don't care condition\n",
    "        # choose it and add it to the list of conditions\n",
    "        condition.append(random.choice(n))\n",
    "    return condition\n",
    "\n",
    "\n",
    "def gen_random_action(heaps: list) -> tuple:\n",
    "    heap_idx = random.randint(0, len(heaps)-1)\n",
    "    quantity = random.randint(1, heaps[heap_idx])\n",
    "    return (heap_idx, quantity)\n",
    "\n",
    "\n",
    "def initialization(pop_size: int, heaps: Nim) -> list:\n",
    "    population = list()\n",
    "    n_heaps = len(heaps.rows)\n",
    "    max_genome_size = MAX_GEN_SIZE_RATIO_INIT*n_heaps\n",
    "\n",
    "    for _ in range(pop_size):\n",
    "        genome_size = random.randint(n_heaps, max_genome_size)\n",
    "        conditions = [gen_random_condition(heaps.rows)\n",
    "                      for _ in range(genome_size)]\n",
    "        actions = [gen_random_action(heaps.rows) for _ in range(genome_size)]\n",
    "        step_size = random.random()\n",
    "        mutation_rate = random.random()\n",
    "        g = Genome(conditions, actions, genome_size,\n",
    "                   step_size, mutation_rate, None)\n",
    "        g.fitness = fitness(g, heaps, FITNESS_STRATEGY)\n",
    "        population.append(g)\n",
    "\n",
    "    return population\n",
    "\n",
    "\n",
    "class EvolutionalPlayer(Player):\n",
    "    def __init__(self, name: str, genome: Genome, strategy: Callable):\n",
    "        super().__init__(name, strategy)\n",
    "        self._genome = genome\n",
    "\n",
    "    @property\n",
    "    def genome(self):\n",
    "        return self._genome\n",
    "\n",
    "\n",
    "def termination_condition(cur_gen: int, stats: list):\n",
    "    best_fitness = stats[-1][1]\n",
    "    if cur_gen >= GENERATIONS or best_fitness >= MAX_BEST_FITNESS:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def evolved_strategy(player: EvolutionalPlayer, heaps: Nim) -> None:\n",
    "    action = player.genome.check_conditions(heaps.rows)\n",
    "\n",
    "    # check if an action is possible\n",
    "    # if not act randomly\n",
    "    if action is not None and heaps.rows[action[0]] >= action[1]:\n",
    "        heaps.nimming(action[0], action[1], player)\n",
    "    else:\n",
    "        non_zero_heaps = [i for i, h in enumerate(heaps.rows) if h > 0]\n",
    "        assert len(non_zero_heaps) > 0\n",
    "        h_idx = random.choice(non_zero_heaps)\n",
    "        q = random.randint(1, heaps.rows[h_idx])\n",
    "        heaps.nimming(h_idx, q, player)\n",
    "\n",
    "\n",
    "def fitness(individual: Genome, heaps: Nim, strategy: Callable) -> float:\n",
    "    this_player = EvolutionalPlayer(\n",
    "        \"this_player\", individual, evolved_strategy)\n",
    "    opponent = Player(\"opponent\", strategy)\n",
    "    winners = match(this_player, opponent, heaps, FITNESS_N_GAMES)\n",
    "    n_win = 0\n",
    "    for w in winners:\n",
    "        if w[0] == \"this_player\":\n",
    "            n_win += 1\n",
    "    return n_win/FITNESS_N_GAMES - GEN_SIZE_PENALTY*individual.genome_size\n",
    "\n",
    "\n",
    "def statistics(population: list) -> tuple:\n",
    "    # mean fitness, best fitness, std dev of fitness\n",
    "    pop_fitness = [i.fitness for i in population]\n",
    "    best = max(population, key=lambda p: p.fitness)\n",
    "    return mean(pop_fitness), best.fitness, stdev(pop_fitness)\n",
    "\n",
    "\n",
    "def stochastic_universal_sampling(parents: list, sel_prob: list):\n",
    "    if OFFSPR_NUM >= len(parents):\n",
    "        return parents\n",
    "    mating_pool = list()\n",
    "    a = list(accumulate(sel_prob, func=operator.add))\n",
    "    cur_member = 0\n",
    "    i = 0\n",
    "    r = random.uniform(0, 1/OFFSPR_NUM)\n",
    "    while cur_member < OFFSPR_NUM:\n",
    "        while r <= a[i]:\n",
    "            mating_pool.append(parents[i])\n",
    "            r += 1/OFFSPR_NUM\n",
    "            cur_member += 1\n",
    "        i += 1\n",
    "    return mating_pool\n",
    "\n",
    "\n",
    "def parent_selection(population: list, s: float = 1.5) -> list:\n",
    "    population.sort(key=lambda g: g.fitness)\n",
    "    mu = len(population)\n",
    "    sel_prob = [(2-s)/mu + 2*r*(s-1)/(mu*(mu-1))\n",
    "                for r, g in enumerate(population)]\n",
    "    return stochastic_universal_sampling(population, sel_prob)\n",
    "\n",
    "\n",
    "def mutation(offsprings: list, heaps: Nim, k: int = 1) -> list:\n",
    "    mutants = list()\n",
    "    tau = k/sqrt(POP_SIZE)\n",
    "    for o in offsprings:\n",
    "        o.mutate(heaps.rows, tau)\n",
    "        o.fitness = fitness(o, heaps, FITNESS_STRATEGY)\n",
    "        mutants.append(o)\n",
    "    return mutants\n",
    "\n",
    "\n",
    "def crossover(parent_1: Genome, parent_2: Genome) -> tuple:\n",
    "    # arithmetic recombination for the following\n",
    "    c1_step_size = ALPHA_XOVER*parent_1.step_size + \\\n",
    "        (1-ALPHA_XOVER)*parent_2.step_size\n",
    "    c2_step_size = ALPHA_XOVER*parent_2.step_size + \\\n",
    "        (1-ALPHA_XOVER)*parent_1.step_size\n",
    "\n",
    "    c1_mutation_rate = ALPHA_XOVER*parent_1.mutation_rate + \\\n",
    "        (1-ALPHA_XOVER)*parent_2.mutation_rate\n",
    "    c2_mutation_rate = ALPHA_XOVER*parent_2.mutation_rate + \\\n",
    "        (1-ALPHA_XOVER)*parent_1.mutation_rate\n",
    "\n",
    "    c1_genome_size = int(ALPHA_XOVER*parent_1.genome_size +\n",
    "                         (1-ALPHA_XOVER)*parent_2.genome_size)\n",
    "    c2_genome_size = int(ALPHA_XOVER*parent_2.genome_size +\n",
    "                         (1-ALPHA_XOVER)*parent_1.genome_size)\n",
    "\n",
    "    # find the shorter parent and the longer parent\n",
    "    if parent_1.genome_size >= parent_2.genome_size:\n",
    "        long_p = parent_1\n",
    "        short_p = parent_2\n",
    "    else:\n",
    "        long_p = parent_2\n",
    "        short_p = parent_1\n",
    "\n",
    "    c1_conditions = list()\n",
    "    c2_conditions = list()\n",
    "    c1_actions = list()\n",
    "    c2_actions = list()\n",
    "\n",
    "    # fill the short parent with the elements of the long parent\n",
    "    for i in range(short_p.genome_size, long_p.genome_size):\n",
    "        short_p.conditions.append(long_p.conditions[i])\n",
    "        short_p.actions.append(long_p.actions[i])\n",
    "\n",
    "    # uniform crossover\n",
    "    for i, cond1, cond2, act1, act2 in zip(range(c1_genome_size), short_p.conditions, long_p.conditions, short_p.actions, long_p.actions):\n",
    "        r = random.random()\n",
    "        if r < 0.5:\n",
    "            c1_conditions.append(cond1)\n",
    "            c1_actions.append(act1)\n",
    "        else:\n",
    "            c1_conditions.append(cond2)\n",
    "            c1_actions.append(act2)\n",
    "\n",
    "    for i, cond1, cond2, act1, act2 in zip(range(c2_genome_size), short_p.conditions, long_p.conditions, short_p.actions, long_p.actions):\n",
    "        r = random.random()\n",
    "        if r < 0.5:\n",
    "            c2_conditions.append(cond1)\n",
    "            c2_actions.append(act1)\n",
    "        else:\n",
    "            c2_conditions.append(cond2)\n",
    "            c2_actions.append(act2)\n",
    "\n",
    "    assert len(c1_conditions) == c1_genome_size and len(\n",
    "        c1_actions) == c1_genome_size\n",
    "    assert len(c2_conditions) == c2_genome_size and len(\n",
    "        c2_actions) == c2_genome_size\n",
    "\n",
    "    # make the childs\n",
    "    c1 = Genome(c1_conditions, c1_actions, c1_genome_size,\n",
    "                c1_step_size, c1_mutation_rate, None)\n",
    "    c2 = Genome(c2_conditions, c2_actions, c2_genome_size,\n",
    "                c2_step_size, c2_mutation_rate, None)\n",
    "\n",
    "    return c1, c2\n",
    "\n",
    "\n",
    "def recombination(mating_pool: list, offspr_num: int) -> list:\n",
    "    offsprings = list()\n",
    "    for _ in range(int(offspr_num/2)):\n",
    "        p1, p2 = tuple(random.choices(mating_pool, k=2))\n",
    "        c1, c2 = crossover(p1, p2)\n",
    "        offsprings.append(c1)\n",
    "        offsprings.append(c2)\n",
    "    return offsprings\n",
    "\n",
    "\n",
    "def survivor_selection(population: list, offsprings: list) -> list:\n",
    "    # (μ, λ) selection + elitism\n",
    "    # gather the elites\n",
    "    elite_fitness = max(population, key=lambda g: g.fitness).fitness\n",
    "    elites = [g for g in population if isclose(\n",
    "        g.fitness, elite_fitness, abs_tol=5e-2)]\n",
    "    offsprings = offsprings + elites\n",
    "    # sort in decreasing order of fitness\n",
    "    offsprings.sort(key=lambda o: o.fitness, reverse=True)\n",
    "    return offsprings[0:POP_SIZE]  # return only the fittest\n",
    "\n",
    "\n",
    "def plot_stats(stats: list):\n",
    "    g = list(range(int(len(stats))))\n",
    "    mean_fitness = [v[0] for v in stats]\n",
    "    best_fitness = [v[1] for v in stats]\n",
    "    stddev_fitness = [v[2] for v in stats]\n",
    "    plt.figure()\n",
    "    plt.plot(g, mean_fitness, label=\"mean fitness\")\n",
    "    plt.plot(g, best_fitness, label=\"best fitness\")\n",
    "    plt.plot(g, stddev_fitness, label=\"std dev fitness\")\n",
    "    plt.xlim((0, len(stats)))\n",
    "    plt.xlabel(\"generation\")\n",
    "    plt.ylabel(\"fitness\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def extinction(population: list, heaps: Nim) -> list:\n",
    "    survivors = random.choices(population, k=int(POP_SIZE*SURVIVOR_FRAC))\n",
    "    offsprings = mutation(recombination(\n",
    "        survivors, POP_SIZE-len(survivors)), heaps)\n",
    "    for o in offsprings:\n",
    "        o.fitness = fitness(o, heaps, FITNESS_STRATEGY)\n",
    "        survivors.append(o)\n",
    "    logging.info(f\"Extinction event\")\n",
    "    return survivors\n",
    "\n",
    "\n",
    "def convergence(mean_fitness: list, num_gen: int = 3) -> bool:\n",
    "    if len(mean_fitness) <= num_gen + 1:\n",
    "        return False\n",
    "    # consider the last num_gen + 1 generations\n",
    "    eval_data = mean_fitness[-(num_gen+1):]\n",
    "    fitness_incr = [(eval_data[i]-eval_data[i-1])\n",
    "                    for i in range(len(eval_data)-1, 0, -1)]\n",
    "    lower_than_thresh = [f for f in fitness_incr if f < CONVERGENCE_THRESHOLD]\n",
    "    if len(lower_than_thresh) >= num_gen:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def evolve_nim_strategy(heaps: Nim) -> list:\n",
    "    stats = list()\n",
    "    population = initialization(\n",
    "        POP_SIZE, heaps)\n",
    "    stats.append(statistics(population))\n",
    "    if EXT_CNT is not None:\n",
    "        extinction_counter = EXT_CNT\n",
    "    else:\n",
    "        extinction_counter = GENERATIONS\n",
    "    logging.info(\n",
    "        f\"Generation {0}, fitness: mean = {stats[-1][0]}, best = {stats[-1][1]}, stddev = {stats[-1][2]}\")\n",
    "\n",
    "    gens = 0\n",
    "    while not termination_condition(gens, stats):\n",
    "        # this to allow an extinction to happen, you also need convergence\n",
    "        extinction_counter -= 1\n",
    "\n",
    "        # extinction routine\n",
    "        # this to avoid an exinction too close to the end of the run\n",
    "        if EXT_CNT is not None and GENERATIONS - gens > EXT_CNT and extinction_counter == 0:\n",
    "            mean_fitness = [f[0] for f in stats]\n",
    "            # see if the mean fitness did converge in the last gens\n",
    "            if convergence(mean_fitness):\n",
    "                population = extinction(\n",
    "                    population, heaps)\n",
    "                extinction_counter = EXT_CNT\n",
    "\n",
    "        # niching for diversity\n",
    "        if NICHES is not None and NICHES > 1:\n",
    "            for n in range(NICHES):\n",
    "                niche = [(i, g)\n",
    "                         for i, g in enumerate(population) if i % NICHES == n]\n",
    "                niche_pop = [t[1] for t in niche]\n",
    "                niche_idx = [t[0] for t in niche]\n",
    "\n",
    "                parents = parent_selection(niche_pop, int(OFFSPR_NUM/NICHES))\n",
    "                offsprings = mutation(recombination(\n",
    "                    parents, int(OFFSPR_NUM/NICHES)), heaps)\n",
    "                niche_pop = survivor_selection(\n",
    "                    niche_pop, offsprings)\n",
    "\n",
    "                # put the niche back into the population\n",
    "                for i, g in zip(niche_idx, niche_pop):\n",
    "                    population[i] = g\n",
    "\n",
    "                # migration: just swap two elements in population\n",
    "                num_migrants = int(MIGRANT_FRAC*POP_SIZE)\n",
    "                exchange_niche = random.randint(0, NICHES-1)\n",
    "\n",
    "                imm_candidates = [(i, g) for i, g in enumerate(\n",
    "                    population) if i % NICHES == exchange_niche]\n",
    "                immigrants = random.choices(imm_candidates, k=num_migrants)\n",
    "                em_candidates = [(i, g) for i, g in enumerate(\n",
    "                    population) if i % NICHES == n]\n",
    "                emigrants = random.choices(em_candidates, k=num_migrants)\n",
    "\n",
    "                for em, im in zip(emigrants, immigrants):\n",
    "                    population[em[0]] = im[1]\n",
    "                    population[im[0]] = em[1]\n",
    "\n",
    "        else:\n",
    "            # whole population, no niching\n",
    "            parents = parent_selection(population)\n",
    "            offsprings = mutation(recombination(\n",
    "                parents, OFFSPR_NUM), heaps)\n",
    "            population = survivor_selection(population, offsprings)\n",
    "\n",
    "        # compute this generation statistics\n",
    "        stats.append(statistics(population))\n",
    "        logging.info(\n",
    "            f\"Generation {gens+1}, fitness: mean = {stats[-1][0]}, best = {stats[-1][1]}, stddev = {stats[-1][2]}\")\n",
    "\n",
    "        # increase generations counter\n",
    "        gens += 1\n",
    "\n",
    "    plot_stats(stats)\n",
    "    solutions = [g for g in population if isclose(\n",
    "        g.fitness, MAX_BEST_FITNESS, abs_tol=0.05)]\n",
    "\n",
    "    return solutions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Generation 0, fitness: mean = 0.0052, best = 0.18, stddev = 0.021058178786105296\n",
      "INFO:root:Generation 1, fitness: mean = 0.02744, best = 0.32, stddev = 0.04604874998031433\n",
      "INFO:root:Generation 2, fitness: mean = 0.05854, best = 0.32, stddev = 0.051898509714839045\n",
      "INFO:root:Generation 3, fitness: mean = 0.09522, best = 0.32, stddev = 0.044794695327225055\n",
      "INFO:root:Generation 4, fitness: mean = 0.12238, best = 0.32, stddev = 0.0458993365768656\n",
      "INFO:root:Generation 5, fitness: mean = 0.15448, best = 0.32, stddev = 0.04744715022135952\n",
      "INFO:root:Generation 6, fitness: mean = 0.19106, best = 0.34, stddev = 0.05066567300294829\n",
      "INFO:root:Generation 7, fitness: mean = 0.22758, best = 0.37, stddev = 0.04607156148379508\n",
      "INFO:root:Generation 8, fitness: mean = 0.25784, best = 0.39, stddev = 0.0453281776313007\n",
      "INFO:root:Generation 9, fitness: mean = 0.28622, best = 0.49, stddev = 0.0496189043746704\n",
      "INFO:root:Generation 10, fitness: mean = 0.30676, best = 0.54, stddev = 0.046646051367896436\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice won 37 times\n",
      "Bob won 63 times\n"
     ]
    }
   ],
   "source": [
    "heaps = Nim(N_HEAPS)\n",
    "solutions = evolve_nim_strategy(heaps)\n",
    "\n",
    "# test on a match against a nim-sum strategy\n",
    "solution = random.choice(solutions)\n",
    "Alice = EvolutionalPlayer(\"Alice\", solution, evolved_strategy)\n",
    "Bob = Player(\"Bob\", nim_sum_strategy)\n",
    "winners = match(Alice, Bob, heaps, N_GAMES)\n",
    "print_match_result(Alice, Bob, winners)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task3.3 MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameNode:\n",
    "    def __init__(self, state: list, parent=None, children: list = None):\n",
    "        self._state = state\n",
    "        self._parent = parent\n",
    "        self._children = children\n",
    "        self._value = 0\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(bytes(self._state))\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        return self._value\n",
    "\n",
    "    @value.setter\n",
    "    def value(self, val):\n",
    "        self._value = val\n",
    "\n",
    "    @property\n",
    "    def parent(self):\n",
    "        return self._parent\n",
    "\n",
    "    @parent.setter\n",
    "    def parent(self, val):\n",
    "        self._parent = val\n",
    "\n",
    "    @property\n",
    "    def children(self):\n",
    "        return self._children\n",
    "\n",
    "    def add_child(self, child):\n",
    "        self._children.append(child)\n",
    "\n",
    "    @property\n",
    "    def state(self):\n",
    "        return self._state\n",
    "\n",
    "\n",
    "def heuristic(node: GameNode, hash_table: dict):\n",
    "    # check if the value of the state has been already computed\n",
    "    h = hash_table.get(node)\n",
    "    if h is None:\n",
    "        code = check_critical_situations(node.state)\n",
    "        if code > 0:\n",
    "            h = float('inf')\n",
    "        elif code < 0:\n",
    "            h = -float('inf')\n",
    "        else:\n",
    "            if nim_sum(node.state) == 0:  # bad state, gotta do a random action\n",
    "                h = -1\n",
    "            else:\n",
    "                h = 1   # can reduce the nim-sum to zero\n",
    "        hash_table[node] = h  # insert in hash_table for later use\n",
    "    return h\n",
    "\n",
    "\n",
    "def minmax(node: GameNode, depth: int, maximising: bool, hash_table: dict):\n",
    "    if depth == 0:\n",
    "        # if the node is a terminal state like [0, 0, 0]\n",
    "        if sum(node.state) == 0:\n",
    "            if maximising:\n",
    "                # i won because the opponent had like [0, 1, 0] and it took the last object\n",
    "                node.value = float('inf')\n",
    "            else:\n",
    "                node.value = -float('inf')  # i lost\n",
    "        else:\n",
    "            node.value = heuristic(node, hash_table)\n",
    "        return node.value\n",
    "    if maximising:\n",
    "        node.value = -float('inf')\n",
    "        for c in node.children:\n",
    "            node.value = max(node.value, minmax(c, depth-1, False, hash_table))\n",
    "        return node.value\n",
    "    else:\n",
    "        node.value = float('inf')\n",
    "        for c in node.children:\n",
    "            node.value = min(node.value, minmax(c, depth-1, True, hash_table))\n",
    "        return node.value\n",
    "\n",
    "\n",
    "def game_tree(state: list, parent: GameNode, depth: int) -> GameNode:\n",
    "    this_node = GameNode(state, parent, list())\n",
    "    if depth > 0:\n",
    "        for i in range(len(state)):\n",
    "            # list all the possible new sizes of the heap state[i]\n",
    "            for j in range(state[i]):\n",
    "                child_state = copy.deepcopy(state)\n",
    "                child_state[i] = j\n",
    "                this_node.add_child(game_tree(child_state, this_node, depth-1))\n",
    "    return this_node\n",
    "\n",
    "\n",
    "class MinMaxPlayer(Player):\n",
    "    def __init__(self, name, strategy, look_ahead):\n",
    "        super().__init__(name, strategy)\n",
    "        self._hash_table = {}\n",
    "        self._look_ahead = look_ahead\n",
    "\n",
    "    def flush_parameters(self):\n",
    "        self._hash_table = {}\n",
    "        super().flush_parameters()\n",
    "\n",
    "    @property\n",
    "    def hash_table(self):\n",
    "        return self._hash_table\n",
    "\n",
    "    @property\n",
    "    def look_ahead(self):\n",
    "        return self._look_ahead\n",
    "\n",
    "\n",
    "def minmax_strategy(player: MinMaxPlayer, heaps: Nim):\n",
    "    depth = player.look_ahead*2  # depth of the tree is the double of plies look ahead\n",
    "\n",
    "    # generate game tree, access it through the root\n",
    "    root = game_tree(heaps.rows, None, depth)\n",
    "\n",
    "    # apply minmax algorithm, return the heuristic value of the action to be taken\n",
    "    chosen_value = minmax(root, depth, True, player.hash_table)\n",
    "\n",
    "    # select actions\n",
    "    viable_children_idxs = [i for i, c in enumerate(\n",
    "        root.children) if c.value == chosen_value]\n",
    "    chosen_child_idx = random.choice(viable_children_idxs)\n",
    "    chosen_child = root.children[chosen_child_idx]\n",
    "\n",
    "    # compute the heap idx and the number of object to take\n",
    "    difference = [i-j for i, j in zip(root.state, chosen_child.state)]\n",
    "    num_objects = max(difference)\n",
    "    chosen_heap = difference.index(num_objects)\n",
    "\n",
    "    # nim the heap\n",
    "    heaps.nimming(chosen_heap, num_objects, player)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice won 88 times\n",
      "Bob won 12 times\n"
     ]
    }
   ],
   "source": [
    "# minmax vs random\n",
    "heaps = Nim(N_HEAPS)\n",
    "Alice = MinMaxPlayer(\"Alice\", minmax_strategy, 1)\n",
    "Bob = Player(\"Bob\", random_strategy)\n",
    "winners = match(Alice, Bob, heaps, N_GAMES)\n",
    "print_match_result(Alice, Bob, winners)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice won 54 times\n",
      "Bob won 46 times\n"
     ]
    }
   ],
   "source": [
    "# minmax vs minmax\n",
    "heaps = Nim(N_HEAPS)\n",
    "Alice = MinMaxPlayer(\"Alice\", minmax_strategy, 1)\n",
    "Bob = MinMaxPlayer(\"Bob\", minmax_strategy, 1)\n",
    "winners = match(Alice, Bob, heaps, N_GAMES)\n",
    "print_match_result(Alice, Bob, winners)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice won 35 times\n",
      "Bob won 65 times\n"
     ]
    }
   ],
   "source": [
    "# minmax vs nimsum\n",
    "heaps = Nim(N_HEAPS)\n",
    "Alice = MinMaxPlayer(\"Alice\", minmax_strategy, 1)\n",
    "Bob = Player(\"Bob\", nim_sum_strategy)\n",
    "winners = match(Alice, Bob, heaps, N_GAMES)\n",
    "print_match_result(Alice, Bob, winners)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Task3.4 Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES = 10_000  # number of episodes\n",
    "PRINT_SIZE = 30  # number of lines of output printed\n",
    "OPP_STRATEGY = nim_sum_strategy  # opponent strategy\n",
    "EXPLORATION_RATE = 0.1  # fraction of times the agent chooses a never tried action\n",
    "MAX_REWARD = 10  # absolute value of the maximum reward\n",
    "DISCOUNT_FACT = 0.9  # discount factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "Action = namedtuple(\"Action\", \"heap quantity\")\n",
    "\n",
    "class RLAgent(Player):\n",
    "    def __init__(self, name: str, explore: bool):\n",
    "        super().__init__(name, rl_strategy)\n",
    "        self._explore = explore\n",
    "        self._Q_table = dict()\n",
    "        self._frequencies = dict()\n",
    "        self._previous_state = None\n",
    "        self._previous_action = None\n",
    "        self._stats = {'SSE':0, 'updated':0, 'discovered':0}\n",
    "\n",
    "    @property\n",
    "    def Q_table(self):\n",
    "        return self._Q_table\n",
    "\n",
    "    @property\n",
    "    def explore(self):\n",
    "        return self._explore\n",
    "\n",
    "    @explore.setter\n",
    "    def explore(self, val):\n",
    "        self._explore = val\n",
    "\n",
    "    @property\n",
    "    def stats(self):\n",
    "        return self._stats\n",
    "\n",
    "    def reward(self, state: tuple) -> float:\n",
    "        return 0\n",
    "\n",
    "    def generate_actions(self, cur_state: tuple) -> list:\n",
    "        cur_actions = list()\n",
    "        # loop for each heap...\n",
    "        for heap_idx, heap_size in enumerate(cur_state):\n",
    "            # ... and for each possible quantity to be taken off\n",
    "            for q in range(1, heap_size+1):\n",
    "\n",
    "                assert q > 0 and q <= heap_size  # check that the quantity is legal\n",
    "\n",
    "                a = Action(heap_idx, q)  # create an Action\n",
    "                cur_actions.append(a)  # add it to the list of legal actions\n",
    "\n",
    "                # the current state is not in the Q-table add it\n",
    "                if cur_state not in self._Q_table:\n",
    "                    self._Q_table[cur_state] = dict()\n",
    "                    self._frequencies[cur_state] = dict()\n",
    "                    self._stats['discovered'] += 1\n",
    "\n",
    "                # if the action for the current state is not in the Q-table add it\n",
    "                if a not in self._Q_table[cur_state]:\n",
    "                    self._Q_table[cur_state][a] = self.reward(\n",
    "                        cur_state)  # compute its reward\n",
    "                    # set its frequency to zero\n",
    "                    self._frequencies[cur_state][a] = 0\n",
    "\n",
    "        return cur_actions\n",
    "\n",
    "    def learning_rate(self) -> float:\n",
    "        # decrease with the frequency to ensure convergence of the utilities\n",
    "        return len(self._Q_table)/(len(self._Q_table) + self._frequencies[self._previous_state][self._previous_action])\n",
    "\n",
    "    def exploration_function(self, state: tuple) -> Action:\n",
    "        r = random.random()\n",
    "        if self._explore and r < EXPLORATION_RATE:  # exploration: choose the action less frequently chosen\n",
    "            action_freqs = [(a, f)\n",
    "                            for a, f in self._frequencies[state].items()]\n",
    "            action_freqs.sort(key=lambda v: v[1])\n",
    "            return action_freqs.pop(0)[0]\n",
    "        else:  # exploitation: choose the action with the highest Q-value\n",
    "            action_Qvals = [(a, q) for a, q in self._Q_table[state].items()]\n",
    "            action_Qvals.sort(key=lambda v: v[1], reverse=True)\n",
    "            return action_Qvals.pop(0)[0]\n",
    "\n",
    "    def policy(self, current_state: Nim):\n",
    "        cur_state = tuple(current_state.rows)\n",
    "\n",
    "        assert cur_state is not None\n",
    "        assert sum(cur_state) > 0\n",
    "        assert cur_state != self._previous_state\n",
    "\n",
    "        # generate legal actions from cur_state and add them to the tables\n",
    "        cur_actions = self.generate_actions(cur_state)\n",
    "\n",
    "        # update previous state\n",
    "        if self._previous_state is not None and self._previous_action is not None:\n",
    "\n",
    "            # increase frequency\n",
    "            self._frequencies[self._previous_state][self._previous_action] += 1\n",
    "\n",
    "            # get current state max Q value (utility)\n",
    "            max_cur_state_Q_val = max(self._Q_table[cur_state].values())  \n",
    "            \n",
    "            # get previous state Q value\n",
    "            prev_state_old_Q_val = self._Q_table[self._previous_state][self._previous_action]\n",
    "\n",
    "            # compute the new Q value of the previous state\n",
    "            prev_state_new_Q_val = prev_state_old_Q_val + self.learning_rate()*(\n",
    "                self.reward(self._previous_state) + DISCOUNT_FACT*max_cur_state_Q_val - prev_state_old_Q_val)\n",
    "\n",
    "            # save it in the Q table\n",
    "            self._Q_table[self._previous_state][self._previous_action] = prev_state_new_Q_val\n",
    "\n",
    "            # add it to the SSE\n",
    "            self._stats['SSE'] += (prev_state_old_Q_val - prev_state_new_Q_val)**2 \n",
    "            self._stats['updated'] += 1\n",
    "\n",
    "        # choose action\n",
    "        selected_action = self.exploration_function(cur_state)\n",
    "\n",
    "        current_state.nimming(selected_action.heap,\n",
    "                              selected_action.quantity, self)\n",
    "\n",
    "        self._previous_state = cur_state\n",
    "        self._previous_action = selected_action\n",
    "\n",
    "    # parameters are flushed before every game, see the play function\n",
    "    def flush_parameters(self) -> None:\n",
    "        self._previous_action = None\n",
    "        self._previous_state = None\n",
    "        self._stats['SSE'] = 0\n",
    "        self._stats['updated'] = 0\n",
    "        self._stats['discovered'] = 0\n",
    "        super().flush_parameters()\n",
    "\n",
    "    def update_final_state(self, won: bool) -> None:\n",
    "\n",
    "        past_val = self._Q_table[self._previous_state][self._previous_action]\n",
    "        assert past_val is not None\n",
    "\n",
    "        if won:\n",
    "            cur_val = MAX_REWARD\n",
    "        else:\n",
    "            cur_val = -MAX_REWARD\n",
    "\n",
    "            self._stats['SSE'] += (past_val - cur_val)**2  # update SSE\n",
    "            self._stats['updated'] += 1  # increase the number of updated states\n",
    "            \n",
    "            # update value\n",
    "            self._Q_table[self._previous_state][self._previous_action] = cur_val\n",
    "\n",
    "    def Q_values_MSE(self) -> float:\n",
    "        # mean squared error of the updated utilities\n",
    "        if self._stats['updated'] > 0:\n",
    "            return self._stats['SSE'] / self._stats['updated']\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "# just a wrapper to make it works with the previous functions\n",
    "def rl_strategy(agent: RLAgent, state: Nim):\n",
    "    agent.policy(state)\n",
    "\n",
    "\n",
    "def reinforcement_learning(heaps: Nim, agent_name: str) -> RLAgent:\n",
    "    agent = RLAgent(agent_name, explore=True)\n",
    "    opp = Player(\"opp\", OPP_STRATEGY)\n",
    "    for e in range(EPISODES):\n",
    "        # returns a list of tuples (winner_name:str, n_plies:int), but here we have only one game\n",
    "        winner = match(agent, opp, heaps, n_games=1)[0]\n",
    "\n",
    "        # update final state, action Q-values with the reward\n",
    "        if winner[0] == agent_name:\n",
    "            agent.update_final_state(won=True)\n",
    "        else:\n",
    "            agent.update_final_state(won=False)\n",
    "\n",
    "        # print infos\n",
    "        if e % int(EPISODES/PRINT_SIZE) == 0:\n",
    "            logging.info(\n",
    "                f\" Episode: {e}, Q-values MSE = {agent.Q_values_MSE()}, updated states = {agent.stats['updated']}, discovered states = {agent.stats['discovered']}\")\n",
    "\n",
    "    return agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root: Episode: 0, Q-values MSE = 14.285714285714286, updated states = 7, discovered states = 7\n",
      "INFO:root: Episode: 333, Q-values MSE = 3.7928242675729704, updated states = 8, discovered states = 0\n",
      "INFO:root: Episode: 666, Q-values MSE = 2.87239700537947e-08, updated states = 8, discovered states = 0\n",
      "INFO:root: Episode: 999, Q-values MSE = 1.2966264376917304e-13, updated states = 8, discovered states = 0\n",
      "INFO:root: Episode: 1332, Q-values MSE = 6.410903020255664, updated states = 6, discovered states = 0\n",
      "INFO:root: Episode: 1665, Q-values MSE = 3.619358717137129, updated states = 9, discovered states = 0\n",
      "INFO:root: Episode: 1998, Q-values MSE = 7.32595913830909e-20, updated states = 4, discovered states = 0\n",
      "INFO:root: Episode: 2331, Q-values MSE = 1.9770817075054663e-17, updated states = 7, discovered states = 0\n",
      "INFO:root: Episode: 2664, Q-values MSE = 7.062510855426667e-22, updated states = 8, discovered states = 0\n",
      "INFO:root: Episode: 2997, Q-values MSE = 5.8029792795388495, updated states = 9, discovered states = 0\n",
      "INFO:root: Episode: 3330, Q-values MSE = 20.111538867517353, updated states = 4, discovered states = 0\n",
      "INFO:root: Episode: 3663, Q-values MSE = 0.0, updated states = 4, discovered states = 0\n",
      "INFO:root: Episode: 3996, Q-values MSE = 1.5777218104420236e-30, updated states = 8, discovered states = 0\n",
      "INFO:root: Episode: 4329, Q-values MSE = 0.0, updated states = 7, discovered states = 0\n",
      "INFO:root: Episode: 4662, Q-values MSE = 9.930271407725254e-18, updated states = 7, discovered states = 0\n",
      "INFO:root: Episode: 4995, Q-values MSE = 0.0, updated states = 6, discovered states = 0\n",
      "INFO:root: Episode: 5328, Q-values MSE = 6.111037538929435, updated states = 7, discovered states = 0\n",
      "INFO:root: Episode: 5661, Q-values MSE = 0.0, updated states = 6, discovered states = 0\n",
      "INFO:root: Episode: 5994, Q-values MSE = 4.714130144314177e-06, updated states = 9, discovered states = 0\n",
      "INFO:root: Episode: 6327, Q-values MSE = 4.954800298841109, updated states = 7, discovered states = 0\n",
      "INFO:root: Episode: 6660, Q-values MSE = 0.0, updated states = 8, discovered states = 0\n",
      "INFO:root: Episode: 6993, Q-values MSE = 0.0, updated states = 8, discovered states = 0\n",
      "INFO:root: Episode: 7326, Q-values MSE = 0.0, updated states = 8, discovered states = 0\n",
      "INFO:root: Episode: 7659, Q-values MSE = 0.0, updated states = 4, discovered states = 0\n",
      "INFO:root: Episode: 7992, Q-values MSE = 10.588290694671057, updated states = 5, discovered states = 0\n",
      "INFO:root: Episode: 8325, Q-values MSE = 0.0, updated states = 8, discovered states = 0\n",
      "INFO:root: Episode: 8658, Q-values MSE = 0.0, updated states = 3, discovered states = 0\n",
      "INFO:root: Episode: 8991, Q-values MSE = 0.0, updated states = 8, discovered states = 0\n",
      "INFO:root: Episode: 9324, Q-values MSE = 0.0001133419340580969, updated states = 4, discovered states = 0\n",
      "INFO:root: Episode: 9657, Q-values MSE = 5.5753426883419245e-05, updated states = 5, discovered states = 0\n",
      "INFO:root: Episode: 9990, Q-values MSE = 0.0, updated states = 7, discovered states = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice won 53 times\n",
      "Bob won 47 times\n"
     ]
    }
   ],
   "source": [
    "heaps = Nim(N_HEAPS)\n",
    "Alice = reinforcement_learning(heaps, \"Alice\")\n",
    "Alice.explore = False\n",
    "Bob = Player(\"Bob\", nim_sum_strategy)\n",
    "winners = match(Alice, Bob, heaps, N_GAMES)\n",
    "print_match_result(Alice, Bob, winners)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "9736098bae0344245c3be8054c814b256168eeaa5b252fe2e1e318181a993fce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
